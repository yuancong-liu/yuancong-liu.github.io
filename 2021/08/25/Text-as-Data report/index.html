<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="YUANCONG.L">
    
    <title>
        
            Text-as-Data Coursework Report |
        
        YUANCONG&#39;s blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.png">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/css/font-awesome.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"blog.yuan-cong.com","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":false,"expand_all":false,"init_open":false},"style":{"primary_color":"#0066CC","avatar":"/images/avatar.jpg","favicon":"/images/logo.png","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":false,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving."},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":false},"code_copy":{"enable":true,"style":"mac"},"pjax":{"enable":true},"lazyload":{"enable":true},"version":"3.4.3"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                YUANCONG&#39;s blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               target="_blank" rel="noopener" href="http://www.yuan-cong.com"
                            >
                                ME
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       target="_blank" rel="noopener" href="http://www.yuan-cong.com">ME</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">Text-as-Data Coursework Report</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/avatar.jpg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">YUANCONG.L</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;2021-08-25 23:12:50
    </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/English/">English</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/Work/">Work</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>15 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <p>Reddit is made of threads which contain posts generated by the users. Your aim in this task is to predict the sentiment polarity of each post individually. The exercise dataset contains target column called “<code>sentiment.polarity</code>” which can take 5 values: “very negative”, “negative”, “neutral”, “positive” and “very positive” (multi-label classification/prediction).</p>
<p>Read dataset:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_data = pd.read_json(<span class="string">&quot;https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_train.json&quot;</span>)</span><br><span class="line">validation_data = pd.read_json(<span class="string">&quot;https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_validation.json&quot;</span>)</span><br><span class="line">test_data = pd.read_json(<span class="string">&quot;https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_test.json&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h2><p>Use the text from the reddit posts (Known as “body”) to train classification models using the Scikit Learn package. The labels to predict are the <code>sentiment.polarity</code> for each post. Conduct experiments using the following combinations of classifier models and feature representations:</p>
<ol>
<li><code>Dummy Classifier</code> with <code>strategy=&quot;most_frequent&quot;</code></li>
<li><code>Dummy Classifier</code> with <code>strategy=&quot;stratified&quot;</code></li>
<li><code>LogisticRegression</code> with <code>One-hot vectorization</code></li>
<li><code>LogisticRegression</code> with <code>TF-IDF vectorization</code> (default settings)</li>
<li><code>SVC Classifier</code> with <code>One-hot vectorization</code> (SVM with RBF kernel, default settings)</li>
<li>An ‘interesting’ classifier model and vectorisation of your choice with appropriate pre-processing</li>
</ol>
<p><strong>Results</strong> - For the above classifiers report the classifier accuracy as well as macro-averaged precision, recall, and F1 (to three decimal places). Show the overall results1 obtained by the classifiers on the training and test sets in one table, and highlight the best performance. For the best performing classifier (by macro F1 in test set) Include a bar chart graph with the F1 score for each class - (sentiment polarity labels on x-axis, F1 score on Y axis).</p>
<h3 id="Explore-dataset"><a href="#Explore-dataset" class="headerlink" title="Explore dataset"></a>Explore dataset</h3><p>There are five types of <code>sentiment.ploraity</code> in the dataset: neutral, positive, negative, very positive and very negative. firstly, counts of the <code>sentiment.poalrity</code> columns of each of the three datasets were conducted and the results are shown in the table below:</p>
<table>
<thead>
<tr>
<th></th>
<th>neutral</th>
<th>positive</th>
<th>negative</th>
<th>very positive</th>
<th>very negative</th>
</tr>
</thead>
<tbody><tr>
<td>training set</td>
<td>7679</td>
<td>3231</td>
<td>878</td>
<td>253</td>
<td>97</td>
</tr>
<tr>
<td>validation set</td>
<td>1961</td>
<td>845</td>
<td>215</td>
<td>73</td>
<td>15</td>
</tr>
<tr>
<td>testing set</td>
<td>2514</td>
<td>1102</td>
<td>282</td>
<td>86</td>
<td>32</td>
</tr>
</tbody></table>
<p>As can be seen from the chart, the distribution of species is uneven, especially the very small proportion of very positive and very negative, which may lead to poor training to result in a high FRP for these two species.</p>
<h3 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">nlp = spacy.load(<span class="string">&#x27;en_core_web_sm&#x27;</span>)</span><br><span class="line">nlp.remove_pipe(<span class="string">&#x27;tagger&#x27;</span>)</span><br><span class="line">nlp.remove_pipe(<span class="string">&#x27;parser&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># download a stopword list</span></span><br><span class="line">nltk.download(<span class="string">&#x27;stopwords&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tokenize</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spacy_tokenize</span>(<span class="params">string</span>):</span></span><br><span class="line">  tokens = <span class="built_in">list</span>()</span><br><span class="line">  doc = nlp(string)</span><br><span class="line">  <span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    tokens.append(token)</span><br><span class="line">  <span class="keyword">return</span> tokens</span><br><span class="line"></span><br><span class="line"><span class="comment"># normalize</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span>(<span class="params">tokens</span>):</span></span><br><span class="line">  normalized_tokens = <span class="built_in">list</span>()</span><br><span class="line">  <span class="keyword">for</span> token <span class="keyword">in</span> tokens:</span><br><span class="line">    normalized = token.text.lower().strip()</span><br><span class="line">    <span class="keyword">if</span> ((token.is_alpha <span class="keyword">or</span> token.is_digit)):</span><br><span class="line">      normalized_tokens.append(normalized)</span><br><span class="line">  <span class="keyword">return</span> normalized_tokens</span><br><span class="line">  <span class="keyword">return</span> normalized_tokens</span><br><span class="line"></span><br><span class="line"><span class="comment"># tokenize and normalize</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize_normalize</span>(<span class="params">string</span>):</span></span><br><span class="line">  <span class="keyword">return</span> normalize(spacy_tokenize(string))</span><br><span class="line"></span><br><span class="line"><span class="comment">## Pass in the tokenizer as the tokenizer to the vectorizer.</span></span><br><span class="line"><span class="comment">## Create a one-hot encoding vectorizer.</span></span><br><span class="line">one_hot_vectorizer = CountVectorizer(tokenizer=tokenize_normalize, binary=<span class="literal">True</span>)</span><br><span class="line">train_features = one_hot_vectorizer.fit_transform(train_data[<span class="string">&#x27;body&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## This creates input features for our classification on all subsets of our collection.</span></span><br><span class="line">validation_features = one_hot_vectorizer.transform(validation_data[<span class="string">&#x27;body&#x27;</span>])</span><br><span class="line">test_features = one_hot_vectorizer.transform(test_data[<span class="string">&#x27;body&#x27;</span>])</span><br><span class="line"></span><br><span class="line">train_labels = train_data[<span class="string">&#x27;sentiment.polarity&#x27;</span>]</span><br><span class="line">validation_labels = validation_data[<span class="string">&#x27;sentiment.polarity&#x27;</span>]</span><br><span class="line">test_labels = test_data[<span class="string">&#x27;sentiment.polarity&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="Discussion-of-classifier-performance"><a href="#Discussion-of-classifier-performance" class="headerlink" title="Discussion of classifier performance"></a>Discussion of classifier performance</h3><p>First we define a evaluation summary function to summarise the scores:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluation_summary</span>(<span class="params">description, predictions, true_labels</span>):</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;Evaluation for: &quot;</span> + description)</span><br><span class="line">  precision = precision_score(predictions, true_labels, average=<span class="string">&#x27;weighted&#x27;</span>)</span><br><span class="line">  recall = recall_score(predictions, true_labels, average=<span class="string">&#x27;weighted&#x27;</span>)</span><br><span class="line">  accuracy = accuracy_score(predictions, true_labels)</span><br><span class="line">  f1_weighted = fbeta_score(predictions, true_labels, <span class="number">1</span>, average=<span class="string">&#x27;weighted&#x27;</span>) <span class="comment">#1 means f_1 measure</span></span><br><span class="line">  f1_macro = fbeta_score(predictions, true_labels, <span class="number">1</span>, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;Classifier &#x27;%s&#x27; has Acc=%0.3f P=%0.3f R=%0.3f F1_w=%0.3f F1_m=%0.3f&quot;</span> % (description,accuracy,precision,recall,f1_weighted,f1_macro))</span><br><span class="line">  <span class="built_in">print</span>(classification_report(predictions, true_labels, digits=<span class="number">3</span>, zero_division = <span class="number">0</span>))</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;\nConfusion matrix:\n&#x27;</span>,confusion_matrix(true_labels, predictions))</span><br></pre></td></tr></table></figure>

<ol>
<li><code>Dummy Classifier</code> with <code>strategy=&quot;most_frequent&quot;</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dummy_mf = DummyClassifier(strategy=<span class="string">&#x27;most_frequent&#x27;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">0.625996015936255</span><br><span class="line">Evaluation for: Dummy Majority</span><br><span class="line">Classifier &#x27;Dummy Majority&#x27; has Acc=0.626 P=1.000 R=0.626 F1_w=0.770 F1_m=0.154</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><code>Dummy Classifier</code> with <code>strategy=&quot;stratified&quot;</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dummy_prior = DummyClassifier(strategy=<span class="string">&#x27;stratified&#x27;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">0.4676294820717131</span><br><span class="line">Evaluation for: Dummy Prior</span><br><span class="line">Classifier &#x27;Dummy Prior&#x27; has Acc=0.462 P=0.463 R=0.462 F1_w=0.462 F1_m=0.190</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><code>LogisticRegression</code> with <code>One-hot vectorization</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(solver=<span class="string">&#x27;saga&#x27;</span>, max_iter = <span class="number">1000</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR onehot</span><br><span class="line">Classifier &#x27;LR onehot&#x27; has Acc=0.748 P=0.787 R=0.748 F1_w=0.763 F1_m=0.476</span><br></pre></td></tr></table></figure>

<ol start="4">
<li><code>LogisticRegression</code> with <code>TF-IDF vectorization</code> (default settings)</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ngram_vectorizer = TfidfVectorizer(tokenizer=tokenize_normalize)</span><br><span class="line">train_features_idf = ngram_vectorizer.fit_transform(train_data[<span class="string">&#x27;body&#x27;</span>])</span><br><span class="line"></span><br><span class="line">validation_features_idf = ngram_vectorizer.transform(validation_data[<span class="string">&#x27;body&#x27;</span>])</span><br><span class="line">test_features_idf = ngram_vectorizer.transform(test_data[<span class="string">&#x27;body&#x27;</span>])</span><br><span class="line"></span><br><span class="line">lr_idf = LogisticRegression(solver=<span class="string">&#x27;saga&#x27;</span>, max_iter = <span class="number">1000</span>)</span><br><span class="line">lr_idf_model = lr_idf.fit(train_features_idf, train_labels)</span><br><span class="line">evaluation_summary(<span class="string">&quot;LR tf-idf&quot;</span>, lr_idf_model.predict(test_features_idf), test_labels)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR tf-idf</span><br><span class="line">Classifier &#x27;LR tf-idf&#x27; has Acc=0.741 P=0.853 R=0.741 F1_w=0.780 F1_m=0.356</span><br></pre></td></tr></table></figure>

<ol start="5">
<li><code>SVC Classifier</code> with <code>One-hot vectorization</code> <strong>(SVM with RBF kernel, default settings)</strong></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">svc = SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: SVC</span><br><span class="line">Classifier &#x27;SVC&#x27; has Acc=0.730 P=0.875 R=0.730 F1_w=0.782 F1_m=0.287</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>An ‘interesting’ classifier model and vectorisation of your choice with appropriate pre-processing</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">7</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: KNN</span><br><span class="line">Classifier &#x27;KNN&#x27; has Acc=0.634 P=0.991 R=0.634 F1_w=0.768 F1_m=0.171</span><br></pre></td></tr></table></figure>

<p>As the results show, the classifier <code>LogisticRegression</code> with <code>One-hot vectorization</code> had the highest accuracy and the highest f1 scores under the weighted average and macro average. The generally low f1 scores may be due to the uneven distribution of the sample, and the unweighted mean may be heavily influenced by the distribution of the sample.<br>With respect to F1 (macro averaged), <code>LogisticRegression</code> with <code>One-hot vectorization</code> scored the highest, and below is the bar chart graph with the F1 score for each class. This result also confirms the above assumption.</p>
<h2 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h2><p>In this task you will improve the effectiveness of the <code>LogisticRegression</code> with <code>TF-IDF</code> vectorisation from Q1.</p>
<ol>
<li><p><strong>Parameter tuning</strong> - Tune the parameters for both the vectoriser and classifier on the validation set (or using CV-fold validation on the train).<br>Your search does <strong>not</strong> need to be exhaustive. Changing all parameters at once is expensive and slow (a full sweep is exponential in the number of parameters). Consider selecting the best parameters sequentially. The resulting tuned model should improve over the baseline TF-IDF model. Report the results in a table with the accuracy, macro-averaged precision, recall, and F1 on the <strong>test data</strong>. Discuss the parameters and values you tried, what helped and what did not and <em>explain why</em> this may be the case.</p>
<ul>
<li>Classifier - <strong>Regularisation</strong> C value (typical values might be powers of 10 (from $10^{-3}$ to $10^5$)</li>
<li>Vectoriser - Parameters: <code>sublinear_tf</code> and <code>max_features</code> (vocabulary size) (in a range None to 50k)</li>
<li>Select another parameter of your choice from the classifier or vectoriser</li>
</ul>
</li>
<li><p><strong>Error analysis</strong> - Manually examine the predictions of your optimised classifier on the test set. Analyse the results for patterns and trends. Hypothesise why common classification errors are made. Report on your error analysis process and summarise your findings.</p>
</li>
</ol>
<p>We have parameters:</p>
<ol>
<li><code>LogisticRegression</code>: <code>C</code> (typical values are powers of 10 (from $10^{-3}$ to $10^5$);</li>
<li><code>TfidfVectorizer</code>: <code>sublinear_tf</code> (False or True) and <code>max_features</code> (in range None to 50k).</li>
</ol>
<h3 id="Attempt-parameter-optimisation"><a href="#Attempt-parameter-optimisation" class="headerlink" title="Attempt parameter optimisation"></a>Attempt parameter optimisation</h3><p>Before the tuning, we have <strong>f1_macro = 0.353</strong>.<br>There we apply grid search aiming to find the best combination of parameters.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">prediction_pipeline = Pipeline([</span><br><span class="line">              (<span class="string">&#x27;selector&#x27;</span>, ItemSelector(key=<span class="string">&#x27;body&#x27;</span>)),</span><br><span class="line">              (<span class="string">&#x27;tf-idf&#x27;</span>, TfidfVectorizer()),</span><br><span class="line">              (<span class="string">&#x27;logreg&#x27;</span>, LogisticRegression(solver=<span class="string">&#x27;saga&#x27;</span>, max_iter = <span class="number">1000</span>))</span><br><span class="line">              ])</span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;logreg__C&#x27;</span>: [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>, <span class="number">1000</span>, <span class="number">10000</span>, <span class="number">100000</span>],</span><br><span class="line">    <span class="string">&#x27;tf-idf__sublinear_tf&#x27;</span>: [<span class="literal">True</span>, <span class="literal">False</span>],</span><br><span class="line">    <span class="string">&#x27;tf-idf__max_features&#x27;</span>: <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">50000</span>, <span class="number">1000</span>),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(prediction_pipeline, param_grid=params, n_jobs=<span class="number">1</span>, verbose=<span class="number">1</span>, scoring=<span class="string">&#x27;f1_macro&#x27;</span>, cv=<span class="number">2</span>)</span><br><span class="line">grid_search.fit(train_data, train_labels)</span><br><span class="line">best_parameters = grid_search.best_estimator_.get_params()</span><br></pre></td></tr></table></figure>

<p>Besides the parameters above, <code>max_df</code> (of <code>TfidfVectorizer</code> in 2 ranges 0 to 1 and greater than 1) are explored to obtain higher score. A grid search was carried out on max_df using the optimal parameters already obtained above.<br>After the grid search, the best combination of parameters as follows is obtained:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Done 1800 out of 1800 | elapsed: 112.3min finished</span><br><span class="line">logreg__C: 100</span><br><span class="line">tf-idf__max_features: 3000</span><br><span class="line">tf-idf__sublinear_tf: False</span><br></pre></td></tr></table></figure>

<p>After the tuning, we have the <strong>f1_macro</strong> increased to <strong>0.541</strong>.</p>
<h3 id="Explore-the-predictions"><a href="#Explore-the-predictions" class="headerlink" title="Explore the predictions"></a>Explore the predictions</h3><p>For text data where the predicted result differs from the true value, it is printed out as below to analyse the exact cause.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># print 20 pieces of mispredicted data</span></span><br><span class="line">predicted = prediction_pipeline_tuned.predict(test_data)</span><br><span class="line"></span><br><span class="line">p = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(test_labels)):</span><br><span class="line">  <span class="keyword">if</span> p &lt; <span class="number">20</span>:</span><br><span class="line">    <span class="keyword">if</span> test_labels[i] != predicted[i]:</span><br><span class="line">      <span class="built_in">print</span>(test_data[<span class="string">&#x27;body&#x27;</span>][i] + <span class="string">&#x27;\n\nTrue label: &#x27;</span> + test_labels[i] + <span class="string">&#x27; Predicted label: &#x27;</span> + predicted[i] + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">      p += <span class="number">1</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>


<ul>
<li>Example 1</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Even better, watch a VOD from [MLG Raleigh](http://tv.majorleaguegaming.com/videos/174-wr4-g2-kiwikaki-vs-nadagast-steppes-of-war-mlg-raleigh-starcraft-2)</span><br><span class="line">The games, the casting, the maps... everything was fucking awful.  Amazing that it was just over one year ago.</span><br><span class="line">True label: neutral Predicted label: positive</span><br></pre></td></tr></table></figure>

<p>Analysis of the statements shows that the sentences contain URL, which may have an impact on the predictions. Also, <em>“Amazing that it was just over one year ago.”</em> uses a positive word like amazing but expresses a negative opinion of the discussion, which could be one of the reasons for the wrong prediction.</p>
<ul>
<li>Example 2</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Your name and your post do not correlate</span><br><span class="line">True label: neutral Predicted label: very positive</span><br></pre></td></tr></table></figure>

<p>It can be seen that the above sentence is a text unrelated to the content of the posting, and the model incorrectly predicts it as very positive. One reason for this may be that the number of samples labelled as <em>very positive</em> is very small, resulting in the model’s poor prediction of a samples labelled as labels which are minority. The other reason might be that the sentence itself does not contain enough information to extract enough features.</p>
<h1 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h1><p>In this task your goal is to add <strong>two features</strong> to (try to) improve <em>sentiment polarity</em> classification performance obtained in Q2.<br>You must implement and describe two new classifier features and add them to the tuned model from Q2. Examples include adding other properties of the posts (or threads), leveraging embedding-based features, different vectorisation approaches, etc. Train the combined model and report accuracy, macro-averaged precision, recall, and F1 on the test data. Include a well-labeled confusion matrix. Discuss the result in reference to Q2 and what helped (or didn’t) and why you think so.</p>
<h3 id="Propose-features"><a href="#Propose-features" class="headerlink" title="Propose features"></a>Propose features</h3><p>In this dataset, in addition to the “body” which contains the content of the postings, there are other features that may be useful for model training.</p>
<ol>
<li><code>title</code>: The title of the post. This is interrelated with body, so it may help in the training of the model.</li>
<li><code>majority_type</code>: the type of thread. May be useful in the analysis of sentiment.</li>
<li><code>author</code>: the username of the poster. The same sentiment polarity may appear when the<br>same user appears.</li>
<li><code>sentiment.subjectivity</code>: the subjectivity of the posting; its value may reflect the sentiment polarity of the user’s statement; for example, looking at the data, it is clear that a lower value may mean that the user tends to be more neutral.<br>The above features will be attempted.</li>
</ol>
<h3 id="Train-validate-and-test-models"><a href="#Train-validate-and-test-models" class="headerlink" title="Train, validate and test models"></a>Train, validate and test models</h3><p>We start by adding single feature from list above to try them out.</p>
<ol>
<li>Add only <code>title</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add only title</span></span><br><span class="line">prediction_pipeline_union = Pipeline([</span><br><span class="line">        (<span class="string">&#x27;union&#x27;</span>, FeatureUnion(</span><br><span class="line">          transformer_list=[</span><br><span class="line">            (<span class="string">&#x27;title&#x27;</span>, Pipeline([</span><br><span class="line">              (<span class="string">&#x27;selector&#x27;</span>, ItemSelector(key=<span class="string">&#x27;title&#x27;</span>)),</span><br><span class="line">              (<span class="string">&#x27;one-hot&#x27;</span>, TfidfVectorizer(norm=<span class="string">&#x27;l1&#x27;</span>)), </span><br><span class="line">              ])),</span><br><span class="line">            (<span class="string">&#x27;body&#x27;</span>, Pipeline([</span><br><span class="line">              (<span class="string">&#x27;selector&#x27;</span>, ItemSelector(key=<span class="string">&#x27;body&#x27;</span>)), </span><br><span class="line">              (<span class="string">&#x27;one-hot&#x27;</span>, TfidfVectorizer(sublinear_tf=<span class="literal">False</span>, max_features=<span class="number">3000</span>, max_df=<span class="number">1200</span>)), </span><br><span class="line">              ])),</span><br><span class="line">        ])</span><br><span class="line">        )</span><br><span class="line">    ])</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR tf-idf</span><br><span class="line">Classifier &#x27;LR tf-idf&#x27; has Acc=0.736 P=0.750 R=0.736 F1_w=0.742 F1_m=0.523</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Add only <code>author</code></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR tf-idf</span><br><span class="line">Classifier &#x27;LR tf-idf&#x27; has Acc=0.738 P=0.776 R=0.738 F1_w=0.752 F1_m=0.501</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Add only <code>majority_type</code></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR tf-idf</span><br><span class="line">Classifier &#x27;LR tf-idf&#x27; has Acc=0.750 P=0.757 R=0.750 F1_w=0.753 F1_m=0.530</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>Add only <code>sentiment.subjectivity</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add only sentiment.subjectivity</span></span><br><span class="line"></span><br><span class="line">numeric_features = [<span class="string">&#x27;sentiment.subjectivity&#x27;</span>]</span><br><span class="line">numeric_transformer = Pipeline(steps=[</span><br><span class="line">    (<span class="string">&#x27;imputer&#x27;</span>, SimpleImputer(strategy=<span class="string">&#x27;median&#x27;</span>)),</span><br><span class="line">    (<span class="string">&#x27;scaler&#x27;</span>, StandardScaler())])</span><br><span class="line"></span><br><span class="line">text_features = [<span class="string">&#x27;body&#x27;</span>]</span><br><span class="line">text_transformer = TfidfVectorizer(sublinear_tf=<span class="literal">False</span>, max_features=<span class="number">3000</span>, max_df=<span class="number">1200</span>)</span><br><span class="line"></span><br><span class="line">preprocessor = ColumnTransformer(</span><br><span class="line">    transformers=[</span><br><span class="line">        (<span class="string">&#x27;num&#x27;</span>, numeric_transformer, numeric_features),</span><br><span class="line">        (<span class="string">&#x27;tfidf_1&#x27;</span>, text_transformer, <span class="string">&#x27;body&#x27;</span>),],</span><br><span class="line">                    remainder=<span class="string">&#x27;drop&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## Run evaluation with classifier</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluateClassifier</span>(<span class="params">classif</span>):</span></span><br><span class="line">  clf = Pipeline(steps=[(<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor),</span><br><span class="line">                        (<span class="string">&#x27;classifier&#x27;</span>, classif)])</span><br><span class="line"></span><br><span class="line">  clf.fit(train_data, train_labels)</span><br><span class="line">  y_pred = clf.predict(test_data)</span><br><span class="line">  <span class="built_in">print</span>(metrics.classification_report(test_labels, y_pred, zero_division=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">evaluateClassifier(LogisticRegression(solver=<span class="string">&#x27;saga&#x27;</span>, max_iter = <span class="number">1000</span>, C=<span class="number">100</span>))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR tf-idf</span><br><span class="line">Classifier &#x27;LR tf-idf&#x27; has Acc=0.790 P=0.780 R=0.790 F1_w=0.790 F1_m=0.600</span><br></pre></td></tr></table></figure>

<p>We can see that with the addition of a single feature, <code>sentiment.subjectivity</code> has the best effect on the model’s effectiveness, raising the f1 score of the model’s macro average from 0.541 to 0.6.<br>Therefore, if two features are to be added, <code>majority_type</code> and <code>subjectivity</code> are probably the best combination of the features listed in the table above.</p>
<ol start="5">
<li>Add two features</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add sentiment.subjectivity and majority_type</span></span><br><span class="line"></span><br><span class="line">numeric_features = [<span class="string">&#x27;sentiment.subjectivity&#x27;</span>]</span><br><span class="line">numeric_transformer = Pipeline(steps=[</span><br><span class="line">    (<span class="string">&#x27;imputer&#x27;</span>, SimpleImputer(strategy=<span class="string">&#x27;median&#x27;</span>)),</span><br><span class="line">    (<span class="string">&#x27;scaler&#x27;</span>, StandardScaler())])</span><br><span class="line"></span><br><span class="line">text_features = [<span class="string">&#x27;body&#x27;</span>, <span class="string">&#x27;majority_type&#x27;</span>]</span><br><span class="line">text_transformer = TfidfVectorizer(sublinear_tf=<span class="literal">False</span>, max_features=<span class="number">3000</span>, max_df=<span class="number">1200</span>)</span><br><span class="line"></span><br><span class="line">preprocessor = ColumnTransformer(</span><br><span class="line">    transformers=[</span><br><span class="line">        (<span class="string">&#x27;num&#x27;</span>, numeric_transformer, numeric_features),</span><br><span class="line">        (<span class="string">&#x27;tfidf_1&#x27;</span>, text_transformer, <span class="string">&#x27;body&#x27;</span>),</span><br><span class="line">        (<span class="string">&#x27;tfidf_2&#x27;</span>, text_transformer, <span class="string">&#x27;majority_type&#x27;</span>)],</span><br><span class="line">                    remainder=<span class="string">&#x27;drop&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## Run evaluation with classifier</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluateClassifier</span>(<span class="params">classif</span>):</span></span><br><span class="line">  clf = Pipeline(steps=[(<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor),</span><br><span class="line">                        (<span class="string">&#x27;classifier&#x27;</span>, classif)])</span><br><span class="line"></span><br><span class="line">  clf.fit(train_data, train_labels)</span><br><span class="line">  y_pred = clf.predict(test_data)</span><br><span class="line">  <span class="built_in">print</span>(metrics.classification_report(test_labels, y_pred, zero_division=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">evaluateClassifier(LogisticRegression(solver=<span class="string">&#x27;saga&#x27;</span>, max_iter = <span class="number">1000</span>, C=<span class="number">100</span>))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR tf-idf</span><br><span class="line">Classifier &#x27;LR tf-idf&#x27; has Acc=0.790 P=0.780 R=0.790 F1_w=0.790 F1_m=0.600</span><br></pre></td></tr></table></figure>

<h3 id="Performance-analysis"><a href="#Performance-analysis" class="headerlink" title="Performance analysis"></a>Performance analysis</h3><p>Comparing the two results shows that the combination of added features has improved all the metrics of the model. Also, there is a slight improvement on the aforementioned poor prediction of a minority labels caused by the uneven sample distribution. Specifically, the proportion improved in scores predicting labels <em>very positive</em> and <em>very negative</em> labels is greater than that in scores of label neutral.</p>
<p>-End-</p>

        </div>

        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2021/08/31/Another2021p3/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">譯 | Another 2001 中文 &lt;#03&gt;</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2021/08/24/Another2021p2/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">譯 | Another 2001 中文 &lt;#02&gt;</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>&nbsp;-&nbsp;
            
            2021&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">YUANCONG.L</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.3</a>
        </div>
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Q1"><span class="nav-text">Q1</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Explore-dataset"><span class="nav-text">Explore dataset</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Preprocessing"><span class="nav-text">Preprocessing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Discussion-of-classifier-performance"><span class="nav-text">Discussion of classifier performance</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Q2"><span class="nav-text">Q2</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Attempt-parameter-optimisation"><span class="nav-text">Attempt parameter optimisation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Explore-the-predictions"><span class="nav-text">Explore the predictions</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Q3"><span class="nav-text">Q3</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Propose-features"><span class="nav-text">Propose features</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Train-validate-and-test-models"><span class="nav-text">Train, validate and test models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Performance-analysis"><span class="nav-text">Performance analysis</span></a></li></ol></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/dark-light-toggle.js"></script>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/local-search.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/code-copy.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/lazyload.js"></script>


<div class="post-scripts pjax">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/toc.js"></script>
    
</div>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.3/source/js/libs/pjax.min.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
