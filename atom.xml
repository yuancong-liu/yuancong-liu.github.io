<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>YUANCONG&#39;s blog</title>
  
  
  <link href="https://blog.yuan-cong.com/atom.xml" rel="self"/>
  
  <link href="https://blog.yuan-cong.com/"/>
  <updated>2021-08-31T10:39:06.263Z</updated>
  <id>https://blog.yuan-cong.com/</id>
  
  <author>
    <name>YUANCONG.L</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>譯 | Another 2001 中文 &lt;#03&gt;</title>
    <link href="https://blog.yuan-cong.com/2021/08/31/Another2021p3/"/>
    <id>https://blog.yuan-cong.com/2021/08/31/Another2021p3/</id>
    <published>2021-08-31T10:35:50.000Z</published>
    <updated>2021-08-31T10:39:06.263Z</updated>
    
    <content type="html"><![CDATA[<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/193508450@N06/51398517739/in/dateposted-public/" title="Another2001"><img src="https://live.staticflickr.com/65535/51398517739_a6c0e38539_b.jpg" width="685" alt="Another2001"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p><h3 id="目录（更新中）"><a href="#目录（更新中）" class="headerlink" title="目录（更新中）"></a>目录（更新中）</h3><ul><li><a href="https://blog.yuan-cong.com/2021/08/24/Another2021p1/">Tuning I</a></li><li><a href="https://blog.yuan-cong.com/2021/08/24/Another2021p1/">Tuning II</a></li><li>Part I ………Y.H.<ul><li><a href="https://blog.yuan-cong.com/2021/08/24/Another2021p2/">Introduction</a></li><li><strong>Chapter 1: April I</strong></li><li>Chapter 2: April II</li><li>Chapter 3: April III</li><li>Chapter 4: April IV</li><li>Chapter 5: April V</li><li>Interlude</li><li>Chapter 6: May I</li></ul></li><li>Part II ………I.A.<ul><li>Chapter 7: May II</li><li>Interlude II</li><li>Chapter 8: June I</li><li>Chapter 9: June II</li><li>Interlude III</li><li>Chapter 10: June III</li><li>Chapter 11: July I</li></ul></li><li>Part III ………M.M.<ul><li>Interlude IV</li><li>Chapter 12: July II</li><li>Chapter 13: August</li><li>Chapter 14: September I</li><li>Chapter 15: September II</li><li>Interlude V</li><li>Chapter 16: September III</li><li>Outroduction</li></ul></li></ul><p>註：由於Markdown語法限制，著重符號改為 <em>斜體</em></p><h2 id="Chapter-1-April-I"><a href="#Chapter-1-April-I" class="headerlink" title="Chapter 1: April I"></a>Chapter 1: April I</h2><h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><p>春天到來，我也終於在升上三年級的前一天完成了搬家。<br>雖說是搬家，但也不是那麼勞神費力的事情。距離上來說，水平方向不到100公尺，垂直方向也只有十幾公尺，也就是簡單地移動了一下一些生活必需品而已。<br>也沒有找搬家公司，而是自己花了幾天時間，一點一點地搬了幾個紙箱子。自己一個人不太搬得動的東西，就麻煩赤澤家的伯父和伯母幫忙了。<br>我的新家位於六層公寓「Freuden飛井」的五樓，E-9房間。<br>整潔的1LDK房間，即使把所有的行李都搬進來，還是覺得寬敞，對於一個初中生來說，一個人住這樣的房間實在是有點奢侈。雖然對於伯父的照顧非常感謝，但還是有一點不太好意思。伯母也提出要幫忙收拾房間，但<br>「謝謝伯母，但沒關係，我自己來就可以了。」<br>「謝謝」和「沒關係」都是我的真實心情。<br>晚飯在 <em>那邊的家</em> 裡吃了之後，我獨自回到了這個我自己一個人的房間——<br>我首先打開了今天最後搬進來的大運動包，取出了其中用浴巾包住的黑色木箱，打開蓋子，看了看裡面。<br>裡面有一個人偶。<br>是穿著黑色裙子的美麗少女的人偶。是所謂的身高大概四十公分的球型關節人偶。這是我所有物品中，數一數二重要的東西。<br>我把這個人偶放在了空空的書架的一角——<br>之後我來到了陽台。<br>四月上旬的晚風吹到臉上還帶著寒意，呼吸也還帶著白氣。<br>天空只有寥寥幾顆星星。今夜應該是滿月之夜，但是被雲遮住了，並不能見其蹤影。<br>我兩手抓著扶手，伸了伸懶腰，重複著安靜的呼吸，望向了外面的風景。<br>過了晚上八點，總的來說夜見山已經燈光昏暗。<br>近處可以看見夜見山川的暗流，以及昏暗的街燈。——河流的對面尚可看見燈火輝煌，那便是紅月町的繁華街。<br>我 <em>回到</em> 這個山間的小城市——夜見山，已經兩年零七個月了。<br>據說我是在夜見山市內的婦產科醫院出生的，之後在這裡居住了一年。之後便和家人離開這裡，到了位於海邊的緋波町，並在那裡生活到了小學六年級的夏天。<br>雖說過去在這裡生活過，但那也是嬰兒時期的故事了，現在什麼也想不起來，所以回到這裡也完全沒有親切感。更多的不如說是在異鄉的不習慣，還有就是，毫無由來的不安和恐慌⋯⋯剛開始是如此，不過兩年多的時間，這些情緒逐漸消失了。<br>⋯⋯但是。<br>我從眼前展開的夜見山夜景中移開目光，長舒一口氣，重重地閉上了眼睛。<br><em>但是，從明天開始。</em><br><em>一切都看明天的情況</em> ，我⋯⋯<br>我閉著眼睛，準備長舒第二口氣的時候——<br>微弱的電子音從房間裡傳來。是手機的鈴聲。</p><h3 id="2"><a href="#2" class="headerlink" title="2"></a>2</h3><p>難道是 <em>她</em> 打來的？<br>我這樣想著，有一些緊張地拿起了銀色的手機。結果期待完全落空了，顯示屏上顯示的是沒有備註名字的電話號碼——<br>「嘿！想？是我，矢木澤。手機好像快壞了，我用家裡座機打給你的。」<br>矢木澤暢之。<br>他是同為夜見山北國中（通稱「夜見北」）的同學。一二年級的時候都是同班，現在得知三年級也被分到了同一班。矢木澤和我有某個共同點，剛認識的時候就發現這個共同點，於是現在保持者一種特別的友誼關係。<br>「怎麼了？」<br>我問道。 <em>她</em> 本來也不愛打電話來⋯⋯我試著這樣安慰自己。<br>「為啥專程用家裡的電話打來？」<br>「也沒怎麼⋯⋯就是有點擔心。明天開始就是第一個學期了。」<br>「嗯。害怕，嗎？」<br>「害怕當然害怕，一想到那種『可能性』就。不過我儘量有不去相信這種事情會發生。」<br>「從之前你就再說了吧。」<br>「我基本上是個樂觀主義者就是了。」<br>「那我不是也沒什麼好擔心的。」<br>「我倒是想聽你說有我這個朋友真好之類的。」<br>傳到我耳朵裡的矢木澤的聲音，和他說的「樂觀主義者」多少有點出入，滲著一些 <em>膽怯</em> 的味道。雖然我這樣覺得，不過也可能是我的過渡臆測。<br>「想到那種『可能性』，就覺得你是不是現在壓力也挺大的。」<br>「是嗎？——不用擔心。」<br>我努力讓自己的回答聽起來足夠冷靜。<br>「我沒關係，也沒有感覺到什麼壓力之類的。」<br>「⋯⋯⋯⋯」<br>「反正還是看明天的情況吧。樂觀主義當然好⋯⋯你懂的。」<br>「啊？」<br>「對於『可能性』。聽好了，臨陣脫逃可行不通喔。」<br>經歷一個短暫的停頓，「啊⋯⋯嗯」的聲音從聽筒傳來了，那是有點急促的聲音。我說著「那明天見。」，掛斷了電話。<br>那之後大概過了一個小時的時間，赤澤家的伯母打來了電話。<br>「想？我忘了說了，明天早上記得到這邊來吃早飯喔！可別不小心睡過頭又慌慌張張不吃早飯喔！」<br>伯母打來電話主要就是想告訴我這件事，我直率地回答了「好」。<br>「要洗的衣服什麼的拿過來就好，洗澡什麼的你就在那邊洗就好了。」<br>伯母真的為我操心很多事情，明明兩個小時之前才互相道了「晚安」。<br>「一個人住會不會不安？」<br>伯母很認真地問了這個問題。<br>「沒關係的，我秋天就十五歲了。」<br>我也這樣認真地回答了。<br>「有什麼需要幫忙的千萬不要客氣⋯⋯到這邊來也行，緊急的時候找樓上的繭子阿姨也行。」<br>「好的，謝謝伯母。」<br>三年前——從我一九九八年九月開始寄宿以來，赤澤家的伯母就非常照顧我。即使知道我家的情況，我的情況，伯母也一直替我著想。<br>我當然也非常感謝伯母。不過，說老實話，我也時常因為這些關心感到壓力。<br>「那就晚安囉，想。」<br>「好的，晚安。」<br>「想」，是我的生父生母給我起的名字。雖然現在姓是「比良塚」，但這個姓終有一天是會扔掉的吧。<br>在那之後我想我會改姓「赤澤」，但還沒有決定好。</p><h3 id="3"><a href="#3" class="headerlink" title="3"></a>3</h3><p>人際關係有些許複雜，我在這裡梳理一下吧。<br>我在夜見山打擾的赤澤家，聽說以前是飛井町附近的大地主。先代（話是這樣說，現在也還健在）赤澤浩宗有三個兒子，老大是春彥，老二是夏彥，然後老三是冬彥。被我叫做「赤澤家的伯父」的是老大的春彥，「赤澤家的伯母」就是他的夫人小百合（*原文為平假名さゆり）。<br>春彥夫婦和年事已高而決定隱居的父親浩宗一起生活。兩年零七個月前，我被接到飛井町裡一塊土地上一棟古老的房子——說得古風一點就是赤澤本家——居住。原因就是在緋波町的老家，比良塚家待不下去了⋯⋯不加修飾的說法的話，就是被趕出來了。<br>從赤澤本家出來徒步大概一兩分鐘的路程就能抵達的「Freuden飛井」實際上是老二夏彥在經營的出租公寓。詳細情況先不講，總的來說就是從四月開始，我將在這裡居住——<br>剛剛的電話中赤澤家的伯母，也就是小百合說的「樓上的繭子阿姨」，其實就是住在這個公寓頂樓的赤澤夏彥的夫人。雖然說這兩位也是赤澤家的伯父伯母，但為了避免混淆我並沒有這樣稱呼他們——<br>所以⋯⋯也就是說。<br>赤澤浩宗有三個兒子，其中老三冬彥，其實就是我的生父。他在我出生不久就去世了，但是——這是我升上國中之後才聽到的故事——他是精神方面出了問題自殺的。</p><h3 id="4"><a href="#4" class="headerlink" title="4"></a>4</h3><p>搬家的紙箱子一個一個打開，把生活必需品都拿出來之後，已經幾乎是午夜了。<br>明天雖有開學典禮，但是要帶走的東西幾乎沒有。從箱子裡面把制服拿出來掛在衣架上，也算暫且把明天的準備做好了。<br>嘴上是說著現在一個人住在公寓裡，但實際上也就是住在一個距離家裡只有一點點距離的臨時安置點——所以房間裡面電視和冰箱什麼的都沒有，因為有手機所以也沒有座機。只是因為要用電腦，所以請人幫忙安裝了電話線來聯網。<br>洗了個澡，算是歇了一口氣之後，為了檢查郵件，打開了筆記本電腦——<br>新郵件有兩封。<br>第一封是叫做「夜見山TOWN通信」的免費郵件雜誌，每個月發行兩次。內容基本上都是沒什麼意思的地區信息和通知之類的，一年前左右不知道怎麼的就訂閱了這個雜誌。<br>另外一通是幸田俊介發來的。<br>我們從一年級開始便是同學，也是生物社的朋友。他從四月開始便擔任起社長一職。和剛才的矢木澤也當然是共同的朋友。<br>關於這一年度的社團活動的計畫安排就佔據了郵件的大半內容，俊介是一個一絲不苟的男生，所以這樣的行為也不是不能理解——但。<br>郵件的最後有一句不太起眼的話，讓我心悸了一下。</p><blockquote><p>祈禱明天開始不要有事情發生。  </p></blockquote><p><em>三年級三班的特殊情況</em> 基本上來說是“內部秘密”，但是居然傳到他的耳朵裡了。雖然這樣的事情沒有傳開反而更奇怪⋯⋯<br>看完兩封郵件，我把放在筆電一旁的手機拿了起來。自從赤澤——小百合阿姨打來之後便沒有人再打來了。<br>我出了一口氣，目光回到了筆電的螢幕上。<br>雖然不打電話，但是郵件一封也不發嗎？我這樣想，可能也是因為我或多或少有些期待接到 <em>她</em> ——MISAKI MEI的聯絡吧。<br>和MEI——見崎鳴最後一次講話，是什麼時候的事情呢？<br>今年有一次⋯⋯不對，有兩次。<br>第一次是過年之後，電話聊了一點。<br>第二次是二月初，我去拜訪御先町的人偶館「夜見黃昏下，虛無蒼之瞳」的時候直接有講到話。<br>二月見面的時候，講了一些 <em>之前的事情</em> 。由於我快要升上三年級了，所以 <em>那</em> 也是不可避免的話題。<br>在那之後，畢業典禮和散學典禮結束之後的幾天後，在我得知四月開始會成為新的三年級三班的成員的時候，我下定決心給她打去了電話，但是重撥了好幾次她也沒接。四月開始之後我也去過一次御先町的人偶館，但是門口貼著「休館」的貼紙⋯⋯<br>我不禁想像她是不是因為什麼長期的家族旅行出遠門了。但是即使不是這樣，四月份開始她也是高三學生了，她自己關於現在和未來應該也有需要考慮⋯⋯吧。<br>我決定總之寫一封報告情況的郵件。<br>報告說之前我的預感果然中了，三年級的班級果然是三班。<br>當然並沒有說麻煩她幫我做些什麼。雖然是三班，但今年也還不見得是「有的一年」。<br>我又出了一口氣，我正準備合上筆電的螢幕。<br>突然傳來了新郵件的提示音。<br>不小心「啊」出了聲，重新握緊了滑鼠，向寄件人一欄投去目光。<br>這是一封沒有標題的郵件，寄件人是⋯⋯<br>「啊啊」<br>不小心出了聲。<br>寄件人名叫「Mei M」——是見崎鳴寄來的郵件。</p><blockquote><p>想<br>學校，是明天開學吧。<br>——要小心。  </p></blockquote><p>比起開心，這個時候更多的是安心的感覺。<br>定睛看著螢幕上的文字，浮現出她——見崎鳴的身影。但是不知道為什麼，不是二月初見到的她，而是三年前的夏天，那個十五歲的戴著眼罩的少女的身影⋯⋯<br>「⋯⋯沒事的」<br>我默默地對自己說道。<br>咬住乾燥的嘴唇，用力伸了伸懶腰。<br>「沒事的。我會努力的。」</p><h3 id="5"><a href="#5" class="headerlink" title="5"></a>5</h3><p>從來到夜見山開始，我逐漸養成了只要不是特別累或是身體不好，都是早上六點半左右起床的習慣。不過還是會害怕會睡過頭，所以為了以防萬一還是有設定鬧鐘。<br>但是醒來我也不會立刻起床。<br>我會先躺著看一會天花板。先確定自己的呼吸、體溫和心跳來確定 <em>現在我還活著</em> 這件事。這一定是三年前的那場奇怪體驗的後遺症。<br>雖然睡覺的地方換了，但是睡醒到起床這一套流程並沒有變化。<br>「好」<br>小聲說著，點點頭，起了身。<br><em>我還活著。</em><br>公元二零零一年四月九日，星期一， <em>我還活著</em> 。——嗯，OK。<br>換了衣服走出房門，給房間上了鎖。<br>門的旁邊有寫著「E-9」的號碼牌，下面有為了放名牌而做的金屬框，但是現在不知道寫什麼，所以就還空著，和公寓大廳的郵箱一樣。<br>兩邊鄰居好像昨天小百合阿姨已經代為問候過了，所以應該不會覺得有奇怪的傢伙搬進來了。我本來也不會受到郵件快遞什麼的，即使是有我的也是赤澤本家幫我代收，所以目前也不會有這方面的問題。<br>這個公寓裡，一樓是A，二樓是B⋯這樣用英文字母表示樓層。我這一層樓其他房間基本都有人住，而且其他房間的構造幾乎都跟E-9不一樣，好像是適合家庭居住的構造。<br>我經過不見人影的早晨走廊，來到了電梯廳。<br>對面映入眼簾的是E-1房間，這個房間像我的一樣，也沒有貼名牌⋯⋯<br>⋯⋯ <em>這裡是</em> 。<br>心裡掠過了一絲疑惑。<br>這裡是？<br>這個房間是⋯⋯<br>有很短暫的一瞬間，世界變成了一片黑暗。<br>咚，好像聽見了一聲巨響。<br>這簡直就像是⋯⋯有點微妙的比喻，就好像是 <em>不在這個世界</em> 的某個人，為了拍下這個畫面，按下了快門。又抑或是一個「黑暗的閃光燈」。<br>這一串胡亂的想像在腦海裡浮現，然後又迅速消失了。<br>甚至是沒有必要在意的，零點零幾秒的超短瞬間，就像是眨了一下眼睛的那一瞬間。<br>然後——<br>之前掠過的疑問，一瞬間消失了。<br>「嗯，這樣啊」<br>我點點頭，拿好書包，按下了下樓的按鈕。<br>早上六點五十分——離上課時間還早得很。</p><h3 id="6"><a href="#6" class="headerlink" title="6"></a>6</h3><p>去赤澤本家那邊吃了早飯，都還離上課還有很長時間。<br>「那我出門了。」<br>我盡量讓自己聽起來很正常，隨後出了家門。比我在這個家裡待的時間更長的黑介（*原文為片假名クロスケ）（黑色公貓，推定年齡八歲），不停「喵喵」叫著跟我走到了門口。是為了目送我⋯⋯當然是沒這個可能。<br>我一般不直接從這裡走到學校。雖說直接走過去也就是十五分鐘左右的腳程，但是我一般都要繞點遠路，走到夜見山川河邊，只要不是天氣特別糟糕，我都會在那裡獨處一陣子。從去年夏天開始不知不覺地就開始這樣做，逐漸這也變成了一天的固定動作——<br>今天早上的夜見山川的水流很平穩。不知道是不是最近都沒下過什麼像樣的雨，水量也不多，感覺都可以走著渡河。<br>天色又一些陰沈，但並不算太冷，穿著學校的制服，感覺剛剛好。只是偶爾吹來一陣風還是會有瞬間的涼意，讓人不禁縮縮脖子。<br>我和平時一樣悠閒地走在河邊的小路上，途中有一些石凳子並排的地方，我坐在了其中一個的上面。<br>我看向對岸，河堤上並排著漂亮的櫻花樹。滿開的時節已經過去，但對我來說，風一吹花瓣就片片落下的場景反而更喜歡。<br>我伸出兩只手，用大拇指和食指圍成一個取景框，將風景框在裡面，在心中「喀嚓」模擬快門的聲音。當然本意是想用真正的相機拍下來的，但是像這樣用假想的相機拍攝，對我來說也還不賴。<br>突然傳來了「欸欸欸欸——」的叫聲。<br>我轉過頭，在上游的小沙洲中看見了剛剛停在地面上的聲音主人。<br>白色羽毛，纖長的脖子和腿⋯⋯是白鷺嗎？<br>但是好像又和平時見到的白鷺不太一樣，它更大，仔細觀察顏色也不是白色，而是有一些泛藍的灰色。從額頭到頭後部有一條黑帶，翅膀的部分也有一些黑色⋯⋯非得說是鷺的話也是蒼鷺吧。<br>這是我第一次在這裡見到這種鳥。<br>想也沒想，我從長椅上站起來，用假想的取景框框住了這一場景——<br>有一個模糊的念頭突然萌生出來。<br>什麼時候⋯⋯我也想帶著專業的單眼相機，到各種各樣的地方去拍照片，向三年前去世的舅舅，賢木晃也舅舅一樣。<br>雖然如此，來到夜見山上了國中，伯父伯母建議我去參加社團活動⋯⋯到頭來加入的也不是攝影社，而是生物社。<br>但是我也不認為這個選擇是一個錯誤。因為我自己也思考過——不能再這樣執著於晃也舅舅了。<br>「現在還⋯⋯」<br>至少，現在還為時尚早。<br>對於現在的我來說，還有不可不做的事情，還有不能不克服的東西。<br>我又坐回長椅上，輕輕閉上了眼睛。<br>流水的聲音，風的聲音，風吹過的觸感，這一切都讓我彷彿從現實遠離開來。鳥再次搧動翅膀叫著飛走的聲音，彷彿也有同樣的距離。<br>像這樣閉著眼睛，直到內心足夠寧靜之後，我才起身離開。<br>蒼鷺早已不見蹤影，取而代之的是貼著河面成群飛過的小型的白鳥。<br>前方可以看見叫做「伊佐那橋」（原文為片假名イザナ）。這座寬度勉強能夠容納兩人擦肩而過的古橋，木製的橋墩和欄杆看起來已經有一些危險。<br>正當我想要回到之前的路上時。<br>「比良塚同學」<br>有人叫了我的名字。<br>「比良塚同——學」<br>在沿河小路上，我後方十幾公尺處，有一個揮動右手的身影。——那是⋯⋯<br>一個穿著夜見北制服的女生，一邊整理著黑色的長髮，一邊一路小跑過來。那是⋯⋯<br>HAZUMI YUIKA——葉住，結香。<br>我記得她是一年級時的同班同學。二年級的時候不同班，但是三年級又是同一班了。雖然沒怎麼說過話，但是名字和臉我都記得很清楚。<br>不過我並沒有停下腳步，而是繼續走了起來。<br>為什麼這個時間她會在這裡？我腦海裡浮現了這個問題⋯⋯但也不是什麼需要深究的事情。<br>「啊」<br>葉住發出有些侷促的聲音，向我追了過來。<br>「別走啊，比良塚同學」<br>聽見她這樣說，我停下了腳步，也是，這也不是需要調轉頭立馬逃跑的人。<br>葉住不一會便追上來，走在我的旁邊。從一年級開始，葉住便是男同學們熱議的「美女」了，先不說大眾的審美基準如何，小臉蛋，再加上工整的五官確實是真的。從現在的年紀來講，葉住稍帶著一絲成熟的氣息。<br>葉住身高和在男生中中等身高的我差不多。及胸的頭髮有一些若隱若現的茶色，不知是天生這樣還是染髮的結果。<br>「那個，比良塚同學」<br>葉住有些不好意思的看著我的側臉說。<br>「明明聽到我打招呼，為什麼先走啊？」<br>與其成熟的氣氛相悖，說的話卻很小孩子氣。我一時什麼也回答不上來。<br>「為什麼？」<br>她更小孩子氣地偏了偏頭。<br>「我聽說你每天早上都在這裡散步，所以。」<br>嗯？原來是這樣嗎？所以她故意算好時間出現在這裡？<br>「比良塚⋯⋯」<br>「我在， <em>練習</em> 」<br>我說道。我並沒有看她，聲音也沒什麼起伏。<br>「還不知道具體怎麼樣，但是之後去了學校，如果⋯⋯」<br>「如果⋯⋯」<br>葉住重複著我說的話，停頓了一兩秒。<br>「呃就是說 <em>如果教室裡面桌椅不夠的話</em> ？」<br>「是的，如果那樣」<br>我第一次把視線放在她的臉上，然後說道。<br>「我知道」<br>葉住有些詭異地點了點頭，不過馬上向我露出了笑臉。<br>「所以啊，就是想著來說一句『請多指教』，所以」<br>「專程到這裡來？」<br>「是」<br>葉住的臉頰有些泛紅，可能是剛才跑過來的緣故吧。<br>「那真是⋯⋯嗯，辛苦你了。」<br>我說道。<br>「之後會怎麼樣，應該很快就會知道了。 <em>到了那個時候</em> ，果然還是要『請多指教』吧。」<br>這個時候和葉住的對話，到此就結束了。總覺得一起走去學校還是有些不自然——<br>「那我先走了」，我說著，留下好像還想說什麼的她獨自離開了。<br>「待會見」<br>我又加上這麼一句。<br>「那個葉住同學，以後可以直接將我『想』嗎？我不太喜歡別人叫我比良塚。」</p><h3 id="7"><a href="#7" class="headerlink" title="7"></a>7</h3><p>到學校是八點四十五分了。<br>開學典禮是9點開始。<br>聚集了校長室和老師辦公室的本部大樓——「A號樓」的門口的通告欄張貼著新學期的分班表，表中按照年級打印了班級成員。三年級三班的成員早在之前就收到了通知，但是以防萬一，我還是去通告欄確認了我自己的名字。隨即便前往開學典禮會場——體育館。<br>體育館裡的學生按照新的班級排列開來⋯⋯我走在其中，盡量不與其他的學生有眼神接觸。即使是昨晚通過電話的矢木澤也好，之前就認識的同學也好，三月份開會的時候才認識的人也好，我都避開他們的視線。<br>視線不交匯，當然我也沒有開口講話⋯⋯我站在隊伍的最後，也不去注意台上講話的老師，就這樣度過了典禮的時間。——心不在這裡。我正如這幾個字所說。<br>開學典禮結束之後，學生們各自朝自己的教室走去。三年級三班的教室在「C號樓」的三樓。<br>我走進教室的時候，教室裡已經有大概半數的同學了。但是，完全沒有這樣的場面應該有的樣子。雖然有小聲交談的人，但是整間教室還是令人窒息的沈默⋯⋯<br>黑板上什麼也沒有寫。雖說是新學期，但天花板上的燈有一盞已經在詭異地忽明忽暗⋯⋯教室裡整整齊齊排列的桌椅，透著讓人不安的感覺。<br>沒有人打算坐下來，甚至沒有人打算把書包放在桌上。<br>「總之，大家先坐下來吧。」<br>有一個女生說道。<br>那是口齒清晰的銳利聲音⋯⋯這個聲音的主人是？<br>咚<br>隨著一聲低響，世界彷彿變成了一片黑暗。我回過神來，「啊原來如此」，想起來， <em>她</em> 就是在三月「對策會議」時選出來的「對策委員」⋯⋯<br>「按照表裡面的號碼順序⋯⋯算了，差不多就行了，總之大家先坐下來吧。」<br>聽到這樣的催促而開始行動的學生也寥寥無幾。<br>不安地環顧四周和面面相覷的同學佔多數，不知為何，其中也有向我投來目光的人，其中有矢木澤，也有其他幾個人。——這樣說來，早晨在河邊見到的葉住也好像想說什麼，看向了我這邊。<br>我不以為意，退到了教室的後門口。<br><em>為了「那個時候」</em> ⋯⋯<br>是的。現在和大家一起坐下來太危險了。<br>不知道是不是需要這麼慎重地行動，也不知道 <em>法則</em> 到底嚴密到什麼地步——但是。<br>小心再小心，這是我關於這件事所制定的方針。<br>終於，老師來了。<br>這時已經落座的學生還不到全部人的半數。<br>「大家早上好」<br>班主任神林老師（女性。推定年齡四十歲前後。理科科任老師。大概是單身）把兩手撐在講桌上說道。<br>「開學典禮大家都辛苦了，我想整個典禮，大家都心不在焉吧。」<br>和三月的會議那時一樣，抑或是更多的緊張，現在充斥著這間教室。<br>不僅僅是我們，我肯定現在老師也非常不安，大概甚至想從這裡直接逃走。<br>神林老師推了推金屬框眼鏡的鼻樑，環顧重新回歸寂靜的教室。<br>「總之，大家現在先請就座。隨便坐就好。」<br>神林老師發出了和對策委員的她相同的指示。一直對於落座猶豫不決的學生，終於聽從了這一指示。不過只有我，獨自一動不動站在教室的後門口。<br>然後，一小會的功夫——<br>在除了我，全體同學都就座的時間點， <em>事態便清晰了起來</em> 。<br>教室裡準備的桌椅，已經全部坐滿了學生了，數量正好。唯一站在門口的我沒有位置可坐。—— <em>教室裡缺了一組桌椅</em> 。<br>「啊⋯⋯」<br>站在講台上的神林老師的口中，彷彿是漏出了這樣顫抖著的聲音。接著，學生中也發出了這樣的聲音⋯⋯包含著各種各樣的感情。<br>葉住結香坐在窗邊最後一排的位置。就在所有人都面朝前方的時候，只有她看著我的方向。<br>我感到她的視線，輕輕點了點頭。<br>然後，我看向講台上的神林老師。注意到我的她，點點頭移開視線。我一言不發離開了教室，開始履行我的職責—— <em>作為今年班裡「不存在的人」</em> 。<br>矢木澤的樂觀猜測果然過於樂觀了。雖然連續兩年都是「沒有的一年」，但是果然沒有 <em>結束</em> 。雖然進入了二十一世紀，但是果然沒有 <em>結束</em> ——果然沒可能結束。<br>以二十九年前MISAKI的死亡為契機開始的三班的特異「現象」，二十九年後的現在也還在繼續⋯⋯而且和我之前預感的一樣， <em>今年</em> —— <em>二零零一學年果然，是「有的一年」</em> 。</p><h3 id="8"><a href="#8" class="headerlink" title="8"></a>8</h3><p>「大家懷著紀念的心情，開始了錯誤的接受方法。對於MISAKI的“死”。」<br>我想起了二月見到見崎鳴的時候她說的話。還有那時我自己說的話。<br>「“死”就是“死”，明明應該好好承認，好好接受。明明應該這樣的⋯⋯」<br>據說，那就是一切的開端。<br>畢業典禮之後拍攝的集體照裡， <em>明明不存在在這個世界上的MISAKI卻出現了</em> 。於是從第二年開始，夜見北的三年級三班裡，開始了不可思議的「現象」。<br>首先，四月新學期開始的時候，教室裡少了一組桌椅。其原因便是——<br>「 <em>班級裡多了一個人，但是誰都沒有注意到。</em> 」<br>關於這個「現象」，國中入學前或多或少有聽到一些事情——從三年前去世的晃也舅舅那裡。<br>但是當自己即將升入三年級的時候，對於這件事情實在是做不到不聽不聞不問了。於是我去向曾經三年三班的學生，「有的一年」的親身經歷者——見崎鳴求助。<br>「無論如何也無法得知到底誰才是『多餘的人』，無論怎麼查，無論怎麼問⋯⋯與其有關的一切，包括花名冊、學校和政府的記錄、甚至是人的記憶，一切的一切都為了合乎『多餘的人』存在的邏輯而被篡改、竄改了。」<br>記錄的篡改。<br>記憶的竄改。<br>「這個『現象』分為『有的一年』和『沒有的一年』⋯⋯也就是說，不是每年都必定會發生。到目前為止都基本是按照兩年會有一次的機率發生，但並沒有看出有什麼規律存在。即使是進了三班，但是是『沒有的一年』的話就會平安度過。不過，如果是『有的一年』的話——」<br>「『災厄』就會降臨吧。」<br>「是的。『多餘的人』混進來的年度，沒有道理的災難就會降臨。每個月，至少一個人，多的時候會有好幾個“相關者”會死去——會成為“死”的一分子。」<br>人們會以各種形式死去⋯⋯事故死，病死，自殺，他殺。按照之前的例子推導出來的規則，“相關者”就是『班級成員及其二等親屬』。學生本人和其父母、兄弟姐妹、包括祖父祖母。<br>到底為什麼班級裡混進來「多餘的人」的話，就會招來「災厄」呢？<br>「因為『多餘的人』的真實身份，其實是『死者』」<br>鳴是這樣解釋的。<br>「以二十九年前的MISAKI的事件為契機，三年級三班變得更接近“死”了吧，班級變成了招徠『死者』的容器，變成了這樣的一個“場”。<br>班級混進「死者」，這正是班級全體接近了“死”的結果。倒過來說，也可以說正是因為混進了「死者」，所以班級更接近“死”了。所以，正因如此——」<br>「三年級三班的“相關者”更 <em>容易死</em> ，更容易成為“死”的一分子。」<br>這個不符合常理的「現象」和「災厄」，在學校立場上，並沒有被公開承認。那樣不科學的“詛咒”一樣的東西，正式組織應該也不會認真對應吧。不過，聽說過去有試過一些非官方的對策。<br>比如說換教室——考慮到“詛咒”是不是和「三年級三班」的位置有關係，不過失敗了。和教室位置沒關係，三班的「現象」和「災厄」還是照樣發生了。<br>又比如說把班級的名字從「一班」「二班」「三班」改成「A班」「B班」「C班」——不過也失敗了，「現象」和「災厄」發生在了「三年級的第三個班」的C班。<br>再比如說，把「三班」去掉，直接改成「一班」「二班」「四班」「五班」「六班」，但是果然也失敗了。「現象」和「災厄」越過三班，發生在了四班的頭上⋯⋯<br>經過這樣那樣的對策，來到了距今十幾年前，終於發現了 <em>某個有效的「對策」</em> ，也就是說——<br>「取代那個『多餘的人』，將班上的一個人定為『不存在的人』。通過這個方法來把班級人數回歸到 <em>原來應有的人數</em> 。也就是將數字吻合起來。本來不應該在的『多餘的人』混進來了，那就用『不存在的人』去中和。」<br>鳴這樣解釋道。<br>「這個方法如果實施得當，那麼即使是『有的一年』也不會發生『災厄』。這個『對策』的成功案例其實有好幾個，那幾年都沒有人死去。自從得知這一方法開始，三年級三班每一年都⋯⋯」<br>在三月末的那次神林老師擔任主持人的「對策會議」——<br>首先選出了主要負責處理圍繞這個「現象」發生的情況的對策委員。然後為了未雨綢繆，「不存在的人」⋯⋯<br>⋯⋯「不存在的人」<br>明明是班級的一員，卻要作為 <em>不存在的人</em> 被對待的人。<br>意味著從第一學期的開頭，到畢業典禮的期間，要被班級全員，甚至是班主任和任課老師作為 <em>不存在的學生</em> 所無視。<br>這個未雨綢繆的重要角色，今年誰會承擔呢？<br>如果有主動站出來的人的話，這樣就很好解決了。如果沒有的話就要靠抽籤來決定⋯⋯這樣的流程或許每年都有一些細微的變化，但似乎總體來講都是這樣——<br>「我來」<br>那個時候我毫無猶豫地舉起了手。<br>「我來當『不存在的人』」<br>班級全員都看向我，目光中包含著複雜的情感。<br>「可以嗎？」<br>這樣向我詢問的神林老師，眼中也充滿了驚訝。<br>「這樣真的可⋯⋯」<br>「是」<br>我稍稍坐正以回應大家的目光。<br>「沒關係，的。」<br>如果可以預防「災厄」的發生的話，那麼四月開始的幾乎一整年時間，作為「不存在的人」——<br>我欣然接受，絕不逃避。<br>早在預料到這種情況的時候我就已經下定了決心。<br>回想三年前的經歷的話，在大家的支持和協助下扮演「不存在的人」並不是什麼難事。<br>我的話沒問題——我這樣說給自己聽。<br>我的話，沒問題。我能好好做的。我能做給他們看。<br>⋯⋯但是。<br>在這之後，出現了沒有預料到的展開。<br>「老師，稍等一下」<br>之前選出來的叫做江藤的對策委員說道。她難掩不安和恐懼，帶著鑽牛角尖的眼神。<br>「這樣就可以了嗎？」<br>她拋出了這樣的問題。<br>「今年的『對策』這樣就可以了嗎？」<br>這之後，作為更深入討論的結果——<br><em>今年的「對策」，追加了一項巨大的變動。</em></p><br><br><br><hr><p>Another 2001<br>by Yukito Ayatsuji<br>Copyright © 2020 by Yukito Ayatsuji<br>First published 2020 in Japan by KADOKAWA CORPORATION</p><p>封面：遠田志帆</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a data-flickr-embed=&quot;true&quot; href=&quot;https://www.flickr.com/photos/193508450@N06/51398517739/in/dateposted-public/&quot; title=&quot;Another2001&quot;&gt;&lt;img</summary>
      
    
    
    
    
    <category term="Chinese" scheme="https://blog.yuan-cong.com/tags/Chinese/"/>
    
    <category term="Translation" scheme="https://blog.yuan-cong.com/tags/Translation/"/>
    
  </entry>
  
  <entry>
    <title>Text-as-Data Coursework Report</title>
    <link href="https://blog.yuan-cong.com/2021/08/25/Text-as-Data%20report/"/>
    <id>https://blog.yuan-cong.com/2021/08/25/Text-as-Data%20report/</id>
    <published>2021-08-25T15:12:50.000Z</published>
    <updated>2021-08-25T15:13:28.082Z</updated>
    
    <content type="html"><![CDATA[<p>Reddit is made of threads which contain posts generated by the users. Your aim in this task is to predict the sentiment polarity of each post individually. The exercise dataset contains target column called “<code>sentiment.polarity</code>” which can take 5 values: “very negative”, “negative”, “neutral”, “positive” and “very positive” (multi-label classification/prediction).</p><p>Read dataset:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_data = pd.read_json(<span class="string">&quot;https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_train.json&quot;</span>)</span><br><span class="line">validation_data = pd.read_json(<span class="string">&quot;https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_validation.json&quot;</span>)</span><br><span class="line">test_data = pd.read_json(<span class="string">&quot;https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_test.json&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h2><p>Use the text from the reddit posts (Known as “body”) to train classification models using the Scikit Learn package. The labels to predict are the <code>sentiment.polarity</code> for each post. Conduct experiments using the following combinations of classifier models and feature representations:</p><ol><li><code>Dummy Classifier</code> with <code>strategy=&quot;most_frequent&quot;</code></li><li><code>Dummy Classifier</code> with <code>strategy=&quot;stratified&quot;</code></li><li><code>LogisticRegression</code> with <code>One-hot vectorization</code></li><li><code>LogisticRegression</code> with <code>TF-IDF vectorization</code> (default settings)</li><li><code>SVC Classifier</code> with <code>One-hot vectorization</code> (SVM with RBF kernel, default settings)</li><li>An ‘interesting’ classifier model and vectorisation of your choice with appropriate pre-processing</li></ol><p><strong>Results</strong> - For the above classifiers report the classifier accuracy as well as macro-averaged precision, recall, and F1 (to three decimal places). Show the overall results1 obtained by the classifiers on the training and test sets in one table, and highlight the best performance. For the best performing classifier (by macro F1 in test set) Include a bar chart graph with the F1 score for each class - (sentiment polarity labels on x-axis, F1 score on Y axis).</p><h3 id="Explore-dataset"><a href="#Explore-dataset" class="headerlink" title="Explore dataset"></a>Explore dataset</h3><p>There are five types of <code>sentiment.ploraity</code> in the dataset: neutral, positive, negative, very positive and very negative. firstly, counts of the <code>sentiment.poalrity</code> columns of each of the three datasets were conducted and the results are shown in the table below:</p><table><thead><tr><th></th><th>neutral</th><th>positive</th><th>negative</th><th>very positive</th><th>very negative</th></tr></thead><tbody><tr><td>training set</td><td>7679</td><td>3231</td><td>878</td><td>253</td><td>97</td></tr><tr><td>validation set</td><td>1961</td><td>845</td><td>215</td><td>73</td><td>15</td></tr><tr><td>testing set</td><td>2514</td><td>1102</td><td>282</td><td>86</td><td>32</td></tr></tbody></table><p>As can be seen from the chart, the distribution of species is uneven, especially the very small proportion of very positive and very negative, which may lead to poor training to result in a high FRP for these two species.</p><h3 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">nlp = spacy.load(<span class="string">&#x27;en_core_web_sm&#x27;</span>)</span><br><span class="line">nlp.remove_pipe(<span class="string">&#x27;tagger&#x27;</span>)</span><br><span class="line">nlp.remove_pipe(<span class="string">&#x27;parser&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># download a stopword list</span></span><br><span class="line">nltk.download(<span class="string">&#x27;stopwords&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tokenize</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spacy_tokenize</span>(<span class="params">string</span>):</span></span><br><span class="line">  tokens = <span class="built_in">list</span>()</span><br><span class="line">  doc = nlp(string)</span><br><span class="line">  <span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    tokens.append(token)</span><br><span class="line">  <span class="keyword">return</span> tokens</span><br><span class="line"></span><br><span class="line"><span class="comment"># normalize</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span>(<span class="params">tokens</span>):</span></span><br><span class="line">  normalized_tokens = <span class="built_in">list</span>()</span><br><span class="line">  <span class="keyword">for</span> token <span class="keyword">in</span> tokens:</span><br><span class="line">    normalized = token.text.lower().strip()</span><br><span class="line">    <span class="keyword">if</span> ((token.is_alpha <span class="keyword">or</span> token.is_digit)):</span><br><span class="line">      normalized_tokens.append(normalized)</span><br><span class="line">  <span class="keyword">return</span> normalized_tokens</span><br><span class="line">  <span class="keyword">return</span> normalized_tokens</span><br><span class="line"></span><br><span class="line"><span class="comment"># tokenize and normalize</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize_normalize</span>(<span class="params">string</span>):</span></span><br><span class="line">  <span class="keyword">return</span> normalize(spacy_tokenize(string))</span><br><span class="line"></span><br><span class="line"><span class="comment">## Pass in the tokenizer as the tokenizer to the vectorizer.</span></span><br><span class="line"><span class="comment">## Create a one-hot encoding vectorizer.</span></span><br><span class="line">one_hot_vectorizer = CountVectorizer(tokenizer=tokenize_normalize, binary=<span class="literal">True</span>)</span><br><span class="line">train_features = one_hot_vectorizer.fit_transform(train_data[<span class="string">&#x27;body&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## This creates input features for our classification on all subsets of our collection.</span></span><br><span class="line">validation_features = one_hot_vectorizer.transform(validation_data[<span class="string">&#x27;body&#x27;</span>])</span><br><span class="line">test_features = one_hot_vectorizer.transform(test_data[<span class="string">&#x27;body&#x27;</span>])</span><br><span class="line"></span><br><span class="line">train_labels = train_data[<span class="string">&#x27;sentiment.polarity&#x27;</span>]</span><br><span class="line">validation_labels = validation_data[<span class="string">&#x27;sentiment.polarity&#x27;</span>]</span><br><span class="line">test_labels = test_data[<span class="string">&#x27;sentiment.polarity&#x27;</span>]</span><br></pre></td></tr></table></figure><h3 id="Discussion-of-classifier-performance"><a href="#Discussion-of-classifier-performance" class="headerlink" title="Discussion of classifier performance"></a>Discussion of classifier performance</h3><p>First we define a evaluation summary function to summarise the scores:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluation_summary</span>(<span class="params">description, predictions, true_labels</span>):</span></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;Evaluation for: &quot;</span> + description)</span><br><span class="line">  precision = precision_score(predictions, true_labels, average=<span class="string">&#x27;weighted&#x27;</span>)</span><br><span class="line">  recall = recall_score(predictions, true_labels, average=<span class="string">&#x27;weighted&#x27;</span>)</span><br><span class="line">  accuracy = accuracy_score(predictions, true_labels)</span><br><span class="line">  f1_weighted = fbeta_score(predictions, true_labels, <span class="number">1</span>, average=<span class="string">&#x27;weighted&#x27;</span>) <span class="comment">#1 means f_1 measure</span></span><br><span class="line">  f1_macro = fbeta_score(predictions, true_labels, <span class="number">1</span>, average=<span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;Classifier &#x27;%s&#x27; has Acc=%0.3f P=%0.3f R=%0.3f F1_w=%0.3f F1_m=%0.3f&quot;</span> % (description,accuracy,precision,recall,f1_weighted,f1_macro))</span><br><span class="line">  <span class="built_in">print</span>(classification_report(predictions, true_labels, digits=<span class="number">3</span>, zero_division = <span class="number">0</span>))</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;\nConfusion matrix:\n&#x27;</span>,confusion_matrix(true_labels, predictions))</span><br></pre></td></tr></table></figure><ol><li><code>Dummy Classifier</code> with <code>strategy=&quot;most_frequent&quot;</code></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dummy_mf = DummyClassifier(strategy=<span class="string">&#x27;most_frequent&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">0.625996015936255</span><br><span class="line">Evaluation for: Dummy Majority</span><br><span class="line">Classifier &#x27;Dummy Majority&#x27; has Acc=0.626 P=1.000 R=0.626 F1_w=0.770 F1_m=0.154</span><br></pre></td></tr></table></figure><ol start="2"><li><code>Dummy Classifier</code> with <code>strategy=&quot;stratified&quot;</code></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dummy_prior = DummyClassifier(strategy=<span class="string">&#x27;stratified&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">0.4676294820717131</span><br><span class="line">Evaluation for: Dummy Prior</span><br><span class="line">Classifier &#x27;Dummy Prior&#x27; has Acc=0.462 P=0.463 R=0.462 F1_w=0.462 F1_m=0.190</span><br></pre></td></tr></table></figure><ol start="3"><li><code>LogisticRegression</code> with <code>One-hot vectorization</code></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(solver=<span class="string">&#x27;saga&#x27;</span>, max_iter = <span class="number">1000</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR onehot</span><br><span class="line">Classifier &#x27;LR onehot&#x27; has Acc=0.748 P=0.787 R=0.748 F1_w=0.763 F1_m=0.476</span><br></pre></td></tr></table></figure><ol start="4"><li><code>LogisticRegression</code> with <code>TF-IDF vectorization</code> (default settings)</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ngram_vectorizer = TfidfVectorizer(tokenizer=tokenize_normalize)</span><br><span class="line">train_features_idf = ngram_vectorizer.fit_transform(train_data[<span class="string">&#x27;body&#x27;</span>])</span><br><span class="line"></span><br><span class="line">validation_features_idf = ngram_vectorizer.transform(validation_data[<span class="string">&#x27;body&#x27;</span>])</span><br><span class="line">test_features_idf = ngram_vectorizer.transform(test_data[<span class="string">&#x27;body&#x27;</span>])</span><br><span class="line"></span><br><span class="line">lr_idf = LogisticRegression(solver=<span class="string">&#x27;saga&#x27;</span>, max_iter = <span class="number">1000</span>)</span><br><span class="line">lr_idf_model = lr_idf.fit(train_features_idf, train_labels)</span><br><span class="line">evaluation_summary(<span class="string">&quot;LR tf-idf&quot;</span>, lr_idf_model.predict(test_features_idf), test_labels)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR tf-idf</span><br><span class="line">Classifier &#x27;LR tf-idf&#x27; has Acc=0.741 P=0.853 R=0.741 F1_w=0.780 F1_m=0.356</span><br></pre></td></tr></table></figure><ol start="5"><li><code>SVC Classifier</code> with <code>One-hot vectorization</code> <strong>(SVM with RBF kernel, default settings)</strong></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">svc = SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: SVC</span><br><span class="line">Classifier &#x27;SVC&#x27; has Acc=0.730 P=0.875 R=0.730 F1_w=0.782 F1_m=0.287</span><br></pre></td></tr></table></figure><ol start="6"><li>An ‘interesting’ classifier model and vectorisation of your choice with appropriate pre-processing</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">7</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: KNN</span><br><span class="line">Classifier &#x27;KNN&#x27; has Acc=0.634 P=0.991 R=0.634 F1_w=0.768 F1_m=0.171</span><br></pre></td></tr></table></figure><p>As the results show, the classifier <code>LogisticRegression</code> with <code>One-hot vectorization</code> had the highest accuracy and the highest f1 scores under the weighted average and macro average. The generally low f1 scores may be due to the uneven distribution of the sample, and the unweighted mean may be heavily influenced by the distribution of the sample.<br>With respect to F1 (macro averaged), <code>LogisticRegression</code> with <code>One-hot vectorization</code> scored the highest, and below is the bar chart graph with the F1 score for each class. This result also confirms the above assumption.</p><h2 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h2><p>In this task you will improve the effectiveness of the <code>LogisticRegression</code> with <code>TF-IDF</code> vectorisation from Q1.</p><ol><li><p><strong>Parameter tuning</strong> - Tune the parameters for both the vectoriser and classifier on the validation set (or using CV-fold validation on the train).<br>Your search does <strong>not</strong> need to be exhaustive. Changing all parameters at once is expensive and slow (a full sweep is exponential in the number of parameters). Consider selecting the best parameters sequentially. The resulting tuned model should improve over the baseline TF-IDF model. Report the results in a table with the accuracy, macro-averaged precision, recall, and F1 on the <strong>test data</strong>. Discuss the parameters and values you tried, what helped and what did not and <em>explain why</em> this may be the case.</p><ul><li>Classifier - <strong>Regularisation</strong> C value (typical values might be powers of 10 (from $10^{-3}$ to $10^5$)</li><li>Vectoriser - Parameters: <code>sublinear_tf</code> and <code>max_features</code> (vocabulary size) (in a range None to 50k)</li><li>Select another parameter of your choice from the classifier or vectoriser</li></ul></li><li><p><strong>Error analysis</strong> - Manually examine the predictions of your optimised classifier on the test set. Analyse the results for patterns and trends. Hypothesise why common classification errors are made. Report on your error analysis process and summarise your findings.</p></li></ol><p>We have parameters:</p><ol><li><code>LogisticRegression</code>: <code>C</code> (typical values are powers of 10 (from $10^{-3}$ to $10^5$);</li><li><code>TfidfVectorizer</code>: <code>sublinear_tf</code> (False or True) and <code>max_features</code> (in range None to 50k).</li></ol><h3 id="Attempt-parameter-optimisation"><a href="#Attempt-parameter-optimisation" class="headerlink" title="Attempt parameter optimisation"></a>Attempt parameter optimisation</h3><p>Before the tuning, we have <strong>f1_macro = 0.353</strong>.<br>There we apply grid search aiming to find the best combination of parameters.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">prediction_pipeline = Pipeline([</span><br><span class="line">              (<span class="string">&#x27;selector&#x27;</span>, ItemSelector(key=<span class="string">&#x27;body&#x27;</span>)),</span><br><span class="line">              (<span class="string">&#x27;tf-idf&#x27;</span>, TfidfVectorizer()),</span><br><span class="line">              (<span class="string">&#x27;logreg&#x27;</span>, LogisticRegression(solver=<span class="string">&#x27;saga&#x27;</span>, max_iter = <span class="number">1000</span>))</span><br><span class="line">              ])</span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;logreg__C&#x27;</span>: [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>, <span class="number">1000</span>, <span class="number">10000</span>, <span class="number">100000</span>],</span><br><span class="line">    <span class="string">&#x27;tf-idf__sublinear_tf&#x27;</span>: [<span class="literal">True</span>, <span class="literal">False</span>],</span><br><span class="line">    <span class="string">&#x27;tf-idf__max_features&#x27;</span>: <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">50000</span>, <span class="number">1000</span>),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">grid_search = GridSearchCV(prediction_pipeline, param_grid=params, n_jobs=<span class="number">1</span>, verbose=<span class="number">1</span>, scoring=<span class="string">&#x27;f1_macro&#x27;</span>, cv=<span class="number">2</span>)</span><br><span class="line">grid_search.fit(train_data, train_labels)</span><br><span class="line">best_parameters = grid_search.best_estimator_.get_params()</span><br></pre></td></tr></table></figure><p>Besides the parameters above, <code>max_df</code> (of <code>TfidfVectorizer</code> in 2 ranges 0 to 1 and greater than 1) are explored to obtain higher score. A grid search was carried out on max_df using the optimal parameters already obtained above.<br>After the grid search, the best combination of parameters as follows is obtained:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Done 1800 out of 1800 | elapsed: 112.3min finished</span><br><span class="line">logreg__C: 100</span><br><span class="line">tf-idf__max_features: 3000</span><br><span class="line">tf-idf__sublinear_tf: False</span><br></pre></td></tr></table></figure><p>After the tuning, we have the <strong>f1_macro</strong> increased to <strong>0.541</strong>.</p><h3 id="Explore-the-predictions"><a href="#Explore-the-predictions" class="headerlink" title="Explore the predictions"></a>Explore the predictions</h3><p>For text data where the predicted result differs from the true value, it is printed out as below to analyse the exact cause.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># print 20 pieces of mispredicted data</span></span><br><span class="line">predicted = prediction_pipeline_tuned.predict(test_data)</span><br><span class="line"></span><br><span class="line">p = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(test_labels)):</span><br><span class="line">  <span class="keyword">if</span> p &lt; <span class="number">20</span>:</span><br><span class="line">    <span class="keyword">if</span> test_labels[i] != predicted[i]:</span><br><span class="line">      <span class="built_in">print</span>(test_data[<span class="string">&#x27;body&#x27;</span>][i] + <span class="string">&#x27;\n\nTrue label: &#x27;</span> + test_labels[i] + <span class="string">&#x27; Predicted label: &#x27;</span> + predicted[i] + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">      p += <span class="number">1</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><ul><li>Example 1</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Even better, watch a VOD from [MLG Raleigh](http://tv.majorleaguegaming.com/videos/174-wr4-g2-kiwikaki-vs-nadagast-steppes-of-war-mlg-raleigh-starcraft-2)</span><br><span class="line">The games, the casting, the maps... everything was fucking awful.  Amazing that it was just over one year ago.</span><br><span class="line">True label: neutral Predicted label: positive</span><br></pre></td></tr></table></figure><p>Analysis of the statements shows that the sentences contain URL, which may have an impact on the predictions. Also, <em>“Amazing that it was just over one year ago.”</em> uses a positive word like amazing but expresses a negative opinion of the discussion, which could be one of the reasons for the wrong prediction.</p><ul><li>Example 2</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Your name and your post do not correlate</span><br><span class="line">True label: neutral Predicted label: very positive</span><br></pre></td></tr></table></figure><p>It can be seen that the above sentence is a text unrelated to the content of the posting, and the model incorrectly predicts it as very positive. One reason for this may be that the number of samples labelled as <em>very positive</em> is very small, resulting in the model’s poor prediction of a samples labelled as labels which are minority. The other reason might be that the sentence itself does not contain enough information to extract enough features.</p><h1 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h1><p>In this task your goal is to add <strong>two features</strong> to (try to) improve <em>sentiment polarity</em> classification performance obtained in Q2.<br>You must implement and describe two new classifier features and add them to the tuned model from Q2. Examples include adding other properties of the posts (or threads), leveraging embedding-based features, different vectorisation approaches, etc. Train the combined model and report accuracy, macro-averaged precision, recall, and F1 on the test data. Include a well-labeled confusion matrix. Discuss the result in reference to Q2 and what helped (or didn’t) and why you think so.</p><h3 id="Propose-features"><a href="#Propose-features" class="headerlink" title="Propose features"></a>Propose features</h3><p>In this dataset, in addition to the “body” which contains the content of the postings, there are other features that may be useful for model training.</p><ol><li><code>title</code>: The title of the post. This is interrelated with body, so it may help in the training of the model.</li><li><code>majority_type</code>: the type of thread. May be useful in the analysis of sentiment.</li><li><code>author</code>: the username of the poster. The same sentiment polarity may appear when the<br>same user appears.</li><li><code>sentiment.subjectivity</code>: the subjectivity of the posting; its value may reflect the sentiment polarity of the user’s statement; for example, looking at the data, it is clear that a lower value may mean that the user tends to be more neutral.<br>The above features will be attempted.</li></ol><h3 id="Train-validate-and-test-models"><a href="#Train-validate-and-test-models" class="headerlink" title="Train, validate and test models"></a>Train, validate and test models</h3><p>We start by adding single feature from list above to try them out.</p><ol><li>Add only <code>title</code></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add only title</span></span><br><span class="line">prediction_pipeline_union = Pipeline([</span><br><span class="line">        (<span class="string">&#x27;union&#x27;</span>, FeatureUnion(</span><br><span class="line">          transformer_list=[</span><br><span class="line">            (<span class="string">&#x27;title&#x27;</span>, Pipeline([</span><br><span class="line">              (<span class="string">&#x27;selector&#x27;</span>, ItemSelector(key=<span class="string">&#x27;title&#x27;</span>)),</span><br><span class="line">              (<span class="string">&#x27;one-hot&#x27;</span>, TfidfVectorizer(norm=<span class="string">&#x27;l1&#x27;</span>)), </span><br><span class="line">              ])),</span><br><span class="line">            (<span class="string">&#x27;body&#x27;</span>, Pipeline([</span><br><span class="line">              (<span class="string">&#x27;selector&#x27;</span>, ItemSelector(key=<span class="string">&#x27;body&#x27;</span>)), </span><br><span class="line">              (<span class="string">&#x27;one-hot&#x27;</span>, TfidfVectorizer(sublinear_tf=<span class="literal">False</span>, max_features=<span class="number">3000</span>, max_df=<span class="number">1200</span>)), </span><br><span class="line">              ])),</span><br><span class="line">        ])</span><br><span class="line">        )</span><br><span class="line">    ])</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR tf-idf</span><br><span class="line">Classifier &#x27;LR tf-idf&#x27; has Acc=0.736 P=0.750 R=0.736 F1_w=0.742 F1_m=0.523</span><br></pre></td></tr></table></figure><ol start="2"><li>Add only <code>author</code></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR tf-idf</span><br><span class="line">Classifier &#x27;LR tf-idf&#x27; has Acc=0.738 P=0.776 R=0.738 F1_w=0.752 F1_m=0.501</span><br></pre></td></tr></table></figure><ol start="3"><li>Add only <code>majority_type</code></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR tf-idf</span><br><span class="line">Classifier &#x27;LR tf-idf&#x27; has Acc=0.750 P=0.757 R=0.750 F1_w=0.753 F1_m=0.530</span><br></pre></td></tr></table></figure><ol start="4"><li>Add only <code>sentiment.subjectivity</code></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add only sentiment.subjectivity</span></span><br><span class="line"></span><br><span class="line">numeric_features = [<span class="string">&#x27;sentiment.subjectivity&#x27;</span>]</span><br><span class="line">numeric_transformer = Pipeline(steps=[</span><br><span class="line">    (<span class="string">&#x27;imputer&#x27;</span>, SimpleImputer(strategy=<span class="string">&#x27;median&#x27;</span>)),</span><br><span class="line">    (<span class="string">&#x27;scaler&#x27;</span>, StandardScaler())])</span><br><span class="line"></span><br><span class="line">text_features = [<span class="string">&#x27;body&#x27;</span>]</span><br><span class="line">text_transformer = TfidfVectorizer(sublinear_tf=<span class="literal">False</span>, max_features=<span class="number">3000</span>, max_df=<span class="number">1200</span>)</span><br><span class="line"></span><br><span class="line">preprocessor = ColumnTransformer(</span><br><span class="line">    transformers=[</span><br><span class="line">        (<span class="string">&#x27;num&#x27;</span>, numeric_transformer, numeric_features),</span><br><span class="line">        (<span class="string">&#x27;tfidf_1&#x27;</span>, text_transformer, <span class="string">&#x27;body&#x27;</span>),],</span><br><span class="line">                    remainder=<span class="string">&#x27;drop&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## Run evaluation with classifier</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluateClassifier</span>(<span class="params">classif</span>):</span></span><br><span class="line">  clf = Pipeline(steps=[(<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor),</span><br><span class="line">                        (<span class="string">&#x27;classifier&#x27;</span>, classif)])</span><br><span class="line"></span><br><span class="line">  clf.fit(train_data, train_labels)</span><br><span class="line">  y_pred = clf.predict(test_data)</span><br><span class="line">  <span class="built_in">print</span>(metrics.classification_report(test_labels, y_pred, zero_division=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">evaluateClassifier(LogisticRegression(solver=<span class="string">&#x27;saga&#x27;</span>, max_iter = <span class="number">1000</span>, C=<span class="number">100</span>))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR tf-idf</span><br><span class="line">Classifier &#x27;LR tf-idf&#x27; has Acc=0.790 P=0.780 R=0.790 F1_w=0.790 F1_m=0.600</span><br></pre></td></tr></table></figure><p>We can see that with the addition of a single feature, <code>sentiment.subjectivity</code> has the best effect on the model’s effectiveness, raising the f1 score of the model’s macro average from 0.541 to 0.6.<br>Therefore, if two features are to be added, <code>majority_type</code> and <code>subjectivity</code> are probably the best combination of the features listed in the table above.</p><ol start="5"><li>Add two features</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add sentiment.subjectivity and majority_type</span></span><br><span class="line"></span><br><span class="line">numeric_features = [<span class="string">&#x27;sentiment.subjectivity&#x27;</span>]</span><br><span class="line">numeric_transformer = Pipeline(steps=[</span><br><span class="line">    (<span class="string">&#x27;imputer&#x27;</span>, SimpleImputer(strategy=<span class="string">&#x27;median&#x27;</span>)),</span><br><span class="line">    (<span class="string">&#x27;scaler&#x27;</span>, StandardScaler())])</span><br><span class="line"></span><br><span class="line">text_features = [<span class="string">&#x27;body&#x27;</span>, <span class="string">&#x27;majority_type&#x27;</span>]</span><br><span class="line">text_transformer = TfidfVectorizer(sublinear_tf=<span class="literal">False</span>, max_features=<span class="number">3000</span>, max_df=<span class="number">1200</span>)</span><br><span class="line"></span><br><span class="line">preprocessor = ColumnTransformer(</span><br><span class="line">    transformers=[</span><br><span class="line">        (<span class="string">&#x27;num&#x27;</span>, numeric_transformer, numeric_features),</span><br><span class="line">        (<span class="string">&#x27;tfidf_1&#x27;</span>, text_transformer, <span class="string">&#x27;body&#x27;</span>),</span><br><span class="line">        (<span class="string">&#x27;tfidf_2&#x27;</span>, text_transformer, <span class="string">&#x27;majority_type&#x27;</span>)],</span><br><span class="line">                    remainder=<span class="string">&#x27;drop&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## Run evaluation with classifier</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluateClassifier</span>(<span class="params">classif</span>):</span></span><br><span class="line">  clf = Pipeline(steps=[(<span class="string">&#x27;preprocessor&#x27;</span>, preprocessor),</span><br><span class="line">                        (<span class="string">&#x27;classifier&#x27;</span>, classif)])</span><br><span class="line"></span><br><span class="line">  clf.fit(train_data, train_labels)</span><br><span class="line">  y_pred = clf.predict(test_data)</span><br><span class="line">  <span class="built_in">print</span>(metrics.classification_report(test_labels, y_pred, zero_division=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">evaluateClassifier(LogisticRegression(solver=<span class="string">&#x27;saga&#x27;</span>, max_iter = <span class="number">1000</span>, C=<span class="number">100</span>))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Evaluation for: LR tf-idf</span><br><span class="line">Classifier &#x27;LR tf-idf&#x27; has Acc=0.790 P=0.780 R=0.790 F1_w=0.790 F1_m=0.600</span><br></pre></td></tr></table></figure><h3 id="Performance-analysis"><a href="#Performance-analysis" class="headerlink" title="Performance analysis"></a>Performance analysis</h3><p>Comparing the two results shows that the combination of added features has improved all the metrics of the model. Also, there is a slight improvement on the aforementioned poor prediction of a minority labels caused by the uneven sample distribution. Specifically, the proportion improved in scores predicting labels <em>very positive</em> and <em>very negative</em> labels is greater than that in scores of label neutral.</p><p>-End-</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Reddit is made of threads which contain posts generated by the users. Your aim in this task is to predict the sentiment polarity of each </summary>
      
    
    
    
    
    <category term="English" scheme="https://blog.yuan-cong.com/tags/English/"/>
    
    <category term="Work" scheme="https://blog.yuan-cong.com/tags/Work/"/>
    
  </entry>
  
  <entry>
    <title>譯 | Another 2001 中文 &lt;#02&gt;</title>
    <link href="https://blog.yuan-cong.com/2021/08/24/Another2021p2/"/>
    <id>https://blog.yuan-cong.com/2021/08/24/Another2021p2/</id>
    <published>2021-08-24T07:40:50.000Z</published>
    <updated>2021-08-31T10:37:28.258Z</updated>
    
    <content type="html"><![CDATA[<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/193508450@N06/51398517739/in/dateposted-public/" title="Another2001"><img src="https://live.staticflickr.com/65535/51398517739_a6c0e38539_b.jpg" width="685" alt="Another2001"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p><h3 id="目录（更新中）"><a href="#目录（更新中）" class="headerlink" title="目录（更新中）"></a>目录（更新中）</h3><ul><li><a href="https://blog.yuan-cong.com/2021/08/24/Another2021p1/">Tuning I</a></li><li><a href="https://blog.yuan-cong.com/2021/08/24/Another2021p1/">Tuning II</a></li><li>Part I ………Y.H.<ul><li><strong>Introduction</strong></li><li><a href="https://blog.yuan-cong.com/2021/08/31/Another2021p3/">Chapter 1: April I</a></li><li>Chapter 2: April II</li><li>Chapter 3: April III</li><li>Chapter 4: April IV</li><li>Chapter 5: April V</li><li>Interlude</li><li>Chapter 6: May I</li></ul></li><li>Part II ………I.A.<ul><li>Chapter 7: May II</li><li>Interlude II</li><li>Chapter 8: June I</li><li>Chapter 9: June II</li><li>Interlude III</li><li>Chapter 10: June III</li><li>Chapter 11: July I</li></ul></li><li>Part III ………M.M.<ul><li>Interlude IV</li><li>Chapter 12: July II</li><li>Chapter 13: August</li><li>Chapter 14: September I</li><li>Chapter 15: September II</li><li>Interlude V</li><li>Chapter 16: September III</li><li>Outroduction</li></ul></li></ul><p>註：由於Markdown語法限制，著重符號改為 <em>斜體</em></p><h1 id="Part-I-………Y-H"><a href="#Part-I-………Y-H" class="headerlink" title="Part I ………Y.H."></a>Part I ………Y.H.</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>說起來，上次的事情，你怎麼想？<br>上次的⋯⋯你是說畢業生們說的那件事？<br>是。那件事你信嗎？<br>不知道。<br>難以置信？<br>——不好說。<br><strong>那樣的“傳達會”每年三月都會開。由前一年的三年級三班給後一年的三年級三班。</strong><br>從接下來的四月開始的新的——三班的分班結果出來的時間點。<br>學校方面也是知道什麼，才會在四月分班結果正式公佈前向學生傳達吧。所以，這件事情應該不是只有學生在擔心。<br>但是啊，再怎麼說，這麼沒道理的事情⋯⋯<br>我倒是聽過一些傳聞。<br><strong>被詛咒的三年級三班</strong>，之類的？<br>是啊。——你呢？<br><strong>因為基本上是秘密啊</strong>，如果不小心告訴其他人，就會有壞事發生之類的。<br>再怎麼說，突然聽到這種故事，一般也不會相信吧。<br>難以置信嗎？<br>你相信嗎？<br>我也不知道。<br>是吧？去年和前年也沒見到他們說的「災厄」之類的事情發生。<br><strong>聽說我們入學之前的那一年是「有的一年」喔。</strong>各種各樣不好的事故和事件發生，然後還有很多人⋯⋯<br><strong>死了。</strong><br>這樣聽起來，果然怪怪的。<br>是這樣的，但是⋯⋯<br>但是？<br>這種關於<strong>“詛咒”真實存在</strong>的故事，果然還是沒辦法當真。<br>這種想法我倒是可以理解。<br>來講話的學長姐不也感覺半信半疑嗎？<br>有嗎？<br>看起來是這樣。<br>嗯。<br>說到底，<strong>二十九年前的MISAKI的故事</strong>本身聽起來不就像是假的嗎？<br>嗯⋯⋯這樣嗎？<br>畢業生為了讓學弟妹害怕搞的什麼慣例的試膽遊戲之類的。<br>嗯嗯。如果真的只是如此也沒關係。<br>這個月底又有集會吧？<br>嗯。說是「對策會議」。<br>真麻煩啊。<br>畢竟有非常認真對待這件事的人在啊。<br>翹掉會不會有麻煩啊？<br>看這氣氛感覺會有。<br>班主任有說過要來嗎？<br>感覺好像這樣說了。<br>唉。沒辦法。</p><p>＊</p><p><strong>幸運的是，去年和前年，也就是說一九九九年和二零零零年，是「沒有的一年」。</strong>進入新世紀了，<strong>會不會就 <em>結束了</em> 。</strong>今年是不是已經不會再有之前的事情了。這樣的想法也不是沒有⋯⋯<br>⋯⋯但是，並沒有「結束了」的證據。<br><strong>如果不僅沒有結束，如果今年——二零零一年也是「有的一年」</strong>，我們必須要為這樣的情況做充分的準備。今天把四月開始就是三班的大家召集起來，就是為了這件事情。<br>今天要講的主要是兩件事情。<br>第一件事是選出<strong>「對策委員」</strong>。<br>第二件事是決定<strong>如果今年是「有的一年」，誰來擔任「不存在的人」。</strong><br>這麼多年來，選對策委員和「不存在的人」的方法每年都不大一樣。今年想把大家召集起來，盡可能多地聽聽大家的意見⋯⋯<br>⋯⋯⋯⋯<br>⋯⋯⋯⋯<br>⋯⋯⋯⋯<br>那，沒有什麼問題吧？<br>按照剛剛決定的，新學期開始之後如果發現是「有的一年」⋯⋯<br>老師，不好意思。<br>怎麼了？<br><strong>這樣就可以了嗎？</strong><br>什麼意思？<br>就是說，<strong>「對策」 <em>僅僅是這樣</em> 就可以了嗎？</strong><br>什麼意思？<br>啊⋯就是說，我聽說，三年前——一九九八年的時候⋯⋯<br>⋯⋯⋯⋯<br>⋯⋯⋯⋯<br>⋯⋯⋯⋯<br>⋯⋯所以，我在想<strong>今年如果我們一開始就做這樣的準備會不會更好，更安全。</strong><br>原來如此。<br>如果今年也是「沒有的一年」當然是最好的。但是是不是還是要盡可能⋯⋯<br>是值得討論的方案呢。——大家怎麼想？</p><br><br><br><hr><p>Another 2001<br>by Yukito Ayatsuji<br>Copyright © 2020 by Yukito Ayatsuji<br>First published 2020 in Japan by KADOKAWA CORPORATION</p><p>封面：遠田志帆</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a data-flickr-embed=&quot;true&quot; href=&quot;https://www.flickr.com/photos/193508450@N06/51398517739/in/dateposted-public/&quot; title=&quot;Another2001&quot;&gt;&lt;img</summary>
      
    
    
    
    
    <category term="Chinese" scheme="https://blog.yuan-cong.com/tags/Chinese/"/>
    
    <category term="Translation" scheme="https://blog.yuan-cong.com/tags/Translation/"/>
    
  </entry>
  
  <entry>
    <title>譯 | Another 2001 中文 &lt;#01&gt;</title>
    <link href="https://blog.yuan-cong.com/2021/08/24/Another2021p1/"/>
    <id>https://blog.yuan-cong.com/2021/08/24/Another2021p1/</id>
    <published>2021-08-23T17:04:50.000Z</published>
    <updated>2021-08-31T10:37:51.874Z</updated>
    
    <content type="html"><![CDATA[<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/193508450@N06/51398517739/in/dateposted-public/" title="Another2001"><img src="https://live.staticflickr.com/65535/51398517739_a6c0e38539_b.jpg" width="685" alt="Another2001"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p><h3 id="目录（更新中）"><a href="#目录（更新中）" class="headerlink" title="目录（更新中）"></a>目录（更新中）</h3><ul><li><strong>Tuning I</strong></li><li><strong>Tuning II</strong></li><li>Part I ………Y.H.<ul><li><a href="https://blog.yuan-cong.com/2021/08/24/Another2021p2/">Introduction</a></li><li><a href="https://blog.yuan-cong.com/2021/08/31/Another2021p3/">Chapter 1: April I</a></li><li>Chapter 2: April II</li><li>Chapter 3: April III</li><li>Chapter 4: April IV</li><li>Chapter 5: April V</li><li>Interlude</li><li>Chapter 6: May I</li></ul></li><li>Part II ………I.A.<ul><li>Chapter 7: May II</li><li>Interlude II</li><li>Chapter 8: June I</li><li>Chapter 9: June II</li><li>Interlude III</li><li>Chapter 10: June III</li><li>Chapter 11: July I</li></ul></li><li>Part III ………M.M.<ul><li>Interlude IV</li><li>Chapter 12: July II</li><li>Chapter 13: August</li><li>Chapter 14: September I</li><li>Chapter 15: September II</li><li>Interlude V</li><li>Chapter 16: September III</li><li>Outroduction</li></ul></li></ul><p>註：由於Markdown語法限制，著重符號改為 <em>斜體</em></p><h2 id="Tuning-I"><a href="#Tuning-I" class="headerlink" title="Tuning I"></a>Tuning I</h2><p>一九七二年。昭和的話是四十七年，<strong>也就是 <em>二十九年前</em> 發生的事情。——那年的春天，夜見山北中學三年級三班的某個學生去世了。</strong>新學期開始，那個學生也剛剛迎來自己的十五歲生日。學校裡面有很多關於死亡原因的傳言，空難也有火車事故也有⋯⋯但據說是因為家裡火災？<br>——好像是。<br>連同父母和小一歲的弟弟，家裡所有人都去世了。<br>——是。<br><strong>那個學生叫MISAKI。</strong>說MASAKI的也有，也不知道是男生還是女生。<br>是MISAKI。<br>是吧。<br><strong>全名是夜見山岬，是男生。</strong><br>YOMIYAMA MISAKI⋯⋯<br>⋯⋯⋯⋯<br><em>他</em> 從一年級開始就成績優異，擅長運動，也很有藝術天賦，長相性格都很好，學生和老師都很喜歡他。但是這樣集合起來，又感覺是騙人的。<br>但是實際上好像就是這樣的。<br>是的。所以⋯⋯大家得知他的死訊，都很受打擊。再怎麼說，那麼受歡迎的人突然死去，同班同學也好，老師也好，大家都沒辦法接受。所以⋯⋯<br><strong>大家懷著紀念的心情，開始了錯誤的接受方法。對於MISAKI的“死”。</strong><br><strong>也就是說，假裝「MISAKI還活著」。</strong><br>是的。<br>MISAKI死了什麼的都是假的。難以置信。不願相信。從這樣的想法開始，逐漸變成了MISAKI還沒死。現在也還活著，看，不就在 <em>這兒</em> 嗎。之後，這樣的事情逐漸升級⋯⋯<br>⋯⋯⋯⋯<br>MISAKI就在 <em>那兒</em> 。實實在在地在那兒。MISAKI還活著。才沒死呢。<strong>⋯⋯三班的所有人在教室裡，全都開始了假裝「MISAKI還活著」的日子。直到畢業的那一天為止。</strong><br>⋯⋯⋯⋯<br>班主任也配合大家，是吧。就像大家說的一樣，MISAKI沒有死。至少在這個教室裡，作為三班的一員，好好地活著，大家這樣想著，連MISAKI的桌椅都保持原樣，大家還在那裡和MISAKI搭話，一起玩，一起放學⋯⋯大家都 <em>假裝</em> 這樣做了。<br>⋯⋯⋯⋯<br>但是——那是錯誤的做法吧。“死”就是“死”，明明應該好好承認，好好接受。明明應該這樣的⋯⋯<br>⋯⋯⋯⋯<br>畢業典禮結束之後，不是大家在教室裡面拍了畢業照嗎？大家看了那張照片，都嚇到了。大家的集體照的角落裡，有不可能的東西被洗了出來。不可能出現在那裡的MISAKI，帶著死人一般蒼白的臉，和大家一樣在笑。<strong>這就是二十九年前的， <em>開始的年份</em> 的⋯⋯</strong><br><strong>成為從第二年開始的三年級三班的不可思議的「現象」的觸發器的事件。</strong><br><strong>「現象」⋯⋯還有伴隨著降臨的悲慘的「災厄」的。</strong><br>是的⋯⋯<br>⋯⋯⋯⋯<br>⋯⋯⋯⋯<br>⋯⋯⋯⋯<br>⋯⋯沒關係嗎？<br>什麼沒關係？<br><strong>這個「現象」，大概並沒有已經因為三年前的 <em>那個</em> 結束。可能還會發生。如果今年，你變成了三班的一員。然後如果⋯⋯</strong><br>啊⋯⋯但是現在開始擔心也沒用。<br>沒用嗎？<br>⋯⋯⋯⋯<br>⋯⋯萬一那樣的事情發生了，要小心。<br>好。但，如果發生了那樣的事，我⋯⋯</p><h2 id="Tuning-II"><a href="#Tuning-II" class="headerlink" title="Tuning II"></a>Tuning II</h2><p><strong>（被認為是）一九九八年的災厄的受害者一覽</strong></p><p><strong>四月</strong><br>藤岡未咲⋯⋯三年級三班的學生，見崎鳴的表妹。本來是雙胞胎妹妹。</p><p><strong>五月</strong><br>櫻木由佳里⋯三年級三班的學生。班長。<br>櫻木三枝子⋯其母。</p><p><strong>六月</strong><br>水野沙苗⋯⋯三年級三班的學生，水野猛的姊姊。<br>高林郁夫⋯⋯三年級三班的學生。</p><p><strong>七月</strong><br>久保寺紹二⋯三年級三班的班主任。國文老師。<br>久保寺德江⋯其母。<br>小椋敦志⋯⋯三年級三班的學生，小椋由實的哥哥。</p><p><strong>八月</strong><br>前島學⋯⋯⋯三年級三班的學生。<br>赤澤泉美⋯⋯同上。<br>米村茂樹⋯⋯同上。<br>杉浦多佳子⋯同上。<br>中尾順太⋯⋯同上。</p><p>沼田謙作⋯⋯“咲谷紀念館”的管理人。高林郁夫的祖父。<br>沼田峯子⋯⋯同上。其妻。</p><br><br><br><hr><p>Another 2001<br>by Yukito Ayatsuji<br>Copyright © 2020 by Yukito Ayatsuji<br>First published 2020 in Japan by KADOKAWA CORPORATION</p><p>封面：遠田志帆</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a data-flickr-embed=&quot;true&quot; href=&quot;https://www.flickr.com/photos/193508450@N06/51398517739/in/dateposted-public/&quot; title=&quot;Another2001&quot;&gt;&lt;img</summary>
      
    
    
    
    
    <category term="Chinese" scheme="https://blog.yuan-cong.com/tags/Chinese/"/>
    
    <category term="Translation" scheme="https://blog.yuan-cong.com/tags/Translation/"/>
    
  </entry>
  
  <entry>
    <title>文 | 加入</title>
    <link href="https://blog.yuan-cong.com/2020/10/16/%E6%96%87-%E5%8A%A0%E5%85%A5/"/>
    <id>https://blog.yuan-cong.com/2020/10/16/%E6%96%87-%E5%8A%A0%E5%85%A5/</id>
    <published>2020-10-16T07:04:50.000Z</published>
    <updated>2021-08-23T17:57:37.021Z</updated>
    
    <content type="html"><![CDATA[<p>“列车进站，请在黄色线后等待，排队上车，谢谢合作。”</p><p>晚上十二点半的的地铁始发站根本看不见几个人，身处一号车厢位置的小李听见语音播报之后抬起头向另一方看，勉强可以看见几个下班应酬结束的醉汉摇摇晃晃的身影。小李从长椅上站起来，把刚刚在自动贩卖机买的饮料塞进包里，叹了口气，走到了玻璃门前。</p><p>“感谢乘坐地铁14号线，本站是本线路首发站A站，开往科技孵化基地。”</p><p>这是一条很怪的地铁线路，从城市的西北边，也就是城市最大的客运中心发车，绕城市半圈多一点，然后在城市的正南边，城市的科技孵化园，也是未来新的市中心抵达终点，是一条修在城郊分界线上的地铁线。<br>奇怪的是，这条线路没有任何一个站是和其他线路互通的，很难想象，一个以交通系统闻名的城市会存在这样一条地铁线路。</p><p>小李的学校在城市的东南边的城郊。在这条线路通车之前，小李的同学们基本过的世外桃源的生活，虽然学校附近也有通公交车，但是因为换乘麻烦，大家也不大想出门。地铁宣布经过学校的时候，学校同学巴不得张灯结彩办个庆典，虽然不是能通到市中心或者是什么繁华地带，但至少孵化园区附近逐渐发展，这两年也有了不少玩乐的去处。</p><p>小李从来没在夜里这个时间，也没在始发站搭过这条地铁。</p><p>室友兼姐妹的小王一边担心小李，一边又忍不住开玩笑。<br>“这大半夜的你可不要碰到痴汉哈。”<br>“你这舌头不想要了我回头把你弄成海的女儿。”<br>“也不错，我觉得我红头发应该也蛮适合的。”<br>“呸，长得丑想得美。”<br>“哼！”</p><p>透过玻璃门看到列车的车头灯越来越近，带着轰鸣声驶入了站台。<br>“我终于要上车了。”小李发给小王。<br>屏幕亮起，面容解锁后，新消息的内容显示了出来。<br>“OK，赶紧回来，我买了酒！”</p><p>短暂的蜂鸣声后，玻璃门打开了，小李走进了车厢，坐在了车厢之间的门边的位置。<br>始发站停留时间比较长。小李一直盯着门。<br>——也不会有人来了，干嘛不关门。<br>终于，关门警告的蜂鸣声响了起来，小李看见远处楼梯上冲下来一个25岁前后的女人，几乎是踉跄着冲过来，在关门的一刹那勉强挤进了地铁。</p><p>“听说这地铁到半夜诡异得很哦，之前听社团的人讲的。”小王发来一条微信。<br>“闭嘴吧你，你啥意思？暗示你要来接我？”<br>“我才懒得。我本来也不信，那学姐讲得绘声绘色，鸡皮疙瘩都给我听起来了。”<br>“你们那社团怎么回事，你们不是轮滑社吗？一天到晚正经社团活动不干，就搞些虚头巴脑的什么半夜讲鬼故事的集会，你小心我明天写血书到社联去举报你们。”<br>小李飞快在手机里打出这一段话，随即又补上一句，“奇了怪了，这儿不是客运站吗，怎么都没人上车啊。”<br>“你以为都像你一样大半夜的坐地铁，这么晚了都打的了吧。”小王打字也飞快。<br>“大半夜的就没火车没飞机了吗？你哪个年代过来的啊？”<br>“小姐，你也不想想你现在坐的这个东西在哪里开啊？”<br>“行吧。”小李放弃争辩。<br>不过想来确实奇怪，即使不是城市人最多的的地方，最大的交通枢纽也算是人流量最大的地方吧，虽然是半夜十二点半，也不应该才这么稀稀拉拉几个人。<br>“可能真的没人半夜坐城乡结合部地铁吧。大概都坐其它线路去市中心过奢华夜生活了。”小李想了想加上一句。<br>“你酸？你不也刚刚过了夜生活回来吗？”<br>“是啊，I had fun with中二病初中生and他的35分数学卷子。”<br>“那也行啊，比我这孤苦伶仃的好。”<br>“喜欢那送给你好了，不用谢。”</p><p>深夜的地铁上，除了行驶的声音，四下都安静地离奇。<br>小李朝隔壁车厢望去，透过车厢之间的门看见的隔壁车厢就好像是接触不稳定的两个空间，在列车的非直线行驶中不断地扭曲。<br>小李看得入神，头一天晚上看的电影《无尽》的画面浮现在脑海里，人们被困在自己的空间里，时间以各自不同的周期不断轮回，但却没有办法逃离。<br>不知道为什么，小李突然觉得自己好像被困在这一个车厢中，而这班列车将永远都没有终点。<br>——是刚刚跟初中生上课上魔怔了吧。</p><p>“啪！”<br>书本掉落的声音把小李从岁月感伤中拉了回来。小李应声望去，是冲刺着上车的女人打开了包，不小心把自己的笔记本给掉在地上了。女人注意到了小李的视线，稍微点了点头以示歉意和尴尬，手忙脚乱地捡起了笔记本。<br>小李打量起眼前这个女人。<br>女人靠在门边，还算干练的职业套装，应该是急忙下班的缘故，工牌还挂在胸前；本应一丝不苟的马尾因为刚才的慌乱有一些散开了，精致但是不显夸张的职业妆容，小李觉得眼前这个女人很符合日剧里面OL的标准形象。<br>——啊，还有美瞳……<br>突然，女人和小李四目相对了。小李难掩尴尬，赶忙别过了眼神。</p><p>“前方到站，B站，左侧车门将开启，请要下车的乘客做好准备。”</p><p>耳机里面不断传来Kpop女团鼓点强烈的电子音乐，配合稍微有些摇晃的地铁，小李开始觉得有些昏昏沉沉。<br>手机突然振动起来。<br>“我好无聊，要不我给你讲14号线怪谈吧，就之前社团学姐讲的。”是小王发来了信息。<br>“你简明扼要讲，讲得太恐怖我就去庙里祈祷你孤独死。”<br>“你太狠了吧。”<br>“赶紧讲，我好赶紧忘。”</p><p>左侧的门齐刷刷地打开，乘客鱼贯而入——说是鱼贯而入，也就是比上一站上车的乘客稍微多了一点，基本填满了座位。隧道中除了换气系统的声音，开始有了一点谈笑的声音。<br>“倒不知道故事是不是真的，但是听起来很邪门。<br>小王像是整理语言很费劲，好半天才发来了第一条信息。</p><p>“据说是14号线刚刚通车的时候发生的事情，大概就是去年的7，8月吧。<br>——嗯？居然在这里还能遇见熟人吗？<br>刚才的女人正在和另外一个女人热络地聊天。<br>“通车仪式才过了几天，有人跑去跟派出所报案，说有人失踪了。<br>这个新上车的女人，穿着几乎相同的职业套装，干练的短发，带着黑框眼镜，除了每天拎的提包之外，胸前还抱着一个文件夹，看起来回到家还要加班的样子。<br>——两个站也隔得不远，是工作上的朋友吧。</p><p>“等等，你在听我讲吗？”<br>小李被手上的振动搞得猛地回过神来。小王才发了两句过来，小李已经开始走神了。<br>“有啊，所以叫你讲快点啊。”<br>“行吧。<br>“有人去派出所报案说有人失踪，说是头一天坐上14号线之后就再也没有消息了。”<br>“什么意思？那人去哪儿了？”<br>“不知道啊。<br>“报案的人说，最后联系上的时候是刚刚上了14号线的时候。据说是对方说上车了，然后就没有消息了。”<br>“这不就是普通的失踪吗，怎么就灵异了？”<br>“着什么急，正要跟你讲啊。”</p><p>“前方到站，C站，左侧车门将开启，请要下车的乘客做好准备。”</p><p>耳机里的女团曲还在继续播放，列车又摇摇晃晃地停在了站台。车门打开，更多的人涌进了车厢，逐渐开始像非高峰期从闹市街区接走玩乐归家红男绿女的深夜快车，小李开始有了一点好歹自己也还是待在一个省会城市的感觉。<br>“据说那个报案的女生自己看起来，怎么讲……<br>“看起来很犹豫。”<br>“啥意思？啥叫看起来很犹豫？”<br>“这里我也觉得很诡异…<br>——熟人怎么这么多？<br>显然，女人的聊天又加入了一个新的女人，或者应该说是女孩，看起来甚至比小李更年轻一些。穿着打扮看起来就像从WEGO的新品目录上照搬下来的一样，虽然说人不可貌相，但小李很难说这两个女人是同一个世界的人。<br>——她们三个在一起会聊什么话题啊……？</p><p>“这个报案的女生，好像不知道失踪的人具体是谁。”<br>“啊？那她报什么案？”<br>“据说当时女生说，那天晚上好像约了一个人见面，但是那个人迟迟没有出现，直到她放弃等对方，最后只有自己回家。<br>“奇怪的是，她不记得那个人是谁了，但是好像是个很重要的人，但是那个人的信息，她一点也想不起来。”<br>“这算哪门子的鬼故事？这不就是啥短期记忆障碍或者单纯闹着玩吧？”<br>“不是，你听我讲。”</p><p>“前方到站，D站，左侧车门将开启，请要下车的乘客做好准备。”</p><p>从这一个站开始，上车的人和下车的人好像开始维持在一个平衡点了，不过再怎么说人不算多，对于一个十二点过发车的车来说，这乘客密度也足够让小李称奇了。小李抬眼看了看电子显示屏，叹了口气。<br>——还有10站……<br>小李突然想起刚上车的时候透过车厢连接门看到的仿佛是异次元的景象，小李又看过去，发现早已被站着的人挡住视线，异次元感荡然无存。</p><p>“警察也没怎么当回事，跟你想的一样，觉得她在开玩笑。<br>“但是奇怪的事情在后面。”<br>“咋？”<br>小李盯着手机顶端的“对方正在输入”终于变回了小王的备注，但是新的信息却迟迟没有来。<br>——怎么不回了？<br>小李的视线重新回到了车门旁的女人们身上。三个女人正在把自己包里的保温或者不保温的水瓶拿出来比较，互相评论对方随身携带的饮料。接着，最开始的女人又从包里拿出来自己随身带着的笔记本。<br>——啊，这是刚刚掉在地上的那个…<br>她把笔记本递给时髦打扮的少女，少女翻阅起来，女人则在旁边给她讲解笔记上的内容，少女则很及时地做出各种各样的反应，甚至还提出问题。接着，少女大致翻完了笔记本，还给了女人，然后女人把笔记本递给了……<br>——嗯？</p><p>……坐在门边第一个位置的男人。<br>不知道为什么，小李开始觉得有些不自在。小李虽然说不上来有什么证据来证明这一点，这个男人一定不是和她们中的任何一个人一起上车的。<br>小李环顾四周，地铁并没有和刚刚有什么区别，人们专注于自己的手机或者是手上的小说，但眼前发生的这些事情，让她觉得有一丝诡异。<br>手机稍显久违地振动起来了。<br>“警察也没把她的话当回事，以为她在开玩笑，差点给她安个什么影响社会安全罪之类的，最后警告了她一下，让她赶紧哪儿来的回哪儿去。”<br>“这就完了？等半天等个这个后续。”<br>“上条消息刚发给你我妈就给我打电话了，你知道的，她老人家话比较多。<br>“还没完哈！女生自己也觉得奇怪，怎么会因为一段不清晰的记忆跑去报案，毕竟自己根本都记不清对方是谁，甚至连对方长什么样子是男是女都不知道。<br>“不过过了两个月，那个女生换了一部新手机，微信自己下载了之前的聊天记录。”<br>“然后呢？”小李开始有一点感觉不舒服了。<br>“置顶的聊天里面有一个没有头像，然后名字也是乱码的聊天记录。”<br>“啊？”</p><p>“前方到站，H站，左侧车门将开启，请要下车的乘客做好准备。”</p><p>——诶？什么时候路过了两站…<br>Kpop女团的音乐声戛然而止，耳机里面突然传来了没电的声音，然后像是耗尽了最后一丝生命力一般，变成了两个没有灵魂的耳塞。小李取下耳机塞进了早已没电的耳机盒。<br>——昨晚记得充电就好了……<br>列车的行进声没了电子音乐与之抗衡，突然显得震耳欲聋。</p><p>“那个聊天记录只有很少的几句话，应该是之前有一大段聊天记录最后只剩下一点。”<br>“写了啥？”<br>“大概女生声称有人失踪前的那天的聊天记录，‘等等我，马上坐车过来’之类的内容。<br>“可是即使是这样，女生依旧回忆不起来对方是谁。”<br>“那聊天记录的对象也不知道是谁？”<br>“不知道，听说女生想了很多办法，问了很多人，没人知道怎么办。<br>“女生甚至去找关系托人去查了那人可能会出现的地方的监控，监控里面也完全没有出现她认识的人。”<br>“就是这个14号线的监控？”<br>“嗯。”</p><p>——他们到底在说什么？<br>小李抬起头来，又看见对面热烈聊天的人们。这次不再是笔记本或者是水瓶了，似乎在讨论一些很热点的时事，偶尔在列车的轰鸣中夹杂着一两个“社会”或者“新闻”之类的字眼传到小李的耳朵里。聊天相当激烈，仿佛随时都会演化成争吵，而且…<br>——怎么有这么多人在讨论？<br>聊天，或许现在应该正确措辞为讨论，正在不断扩大其规模，从门边那几个女人开始，向整个车厢蔓延。小李觉得有点恐慌，但是又实在是想不出来一个能够被别人接受的恐慌的理由。<br>——不过就是很多人在聊天罢了。</p><p>“前方到站，J站，左侧车门将开启，请要下车的乘客做好准备。”</p><p>“后来女生发了微博，描述她遇见的这个很妙的事件，居然有人回应她说自己也有类似的经历。”<br>“也有认识的人失踪了？”<br>“对，也是事后完全想不起来这个人是谁，而且也是坐了14号线。“<br>“那后来两个人有找到什么线索吗？”<br>“完全没有，而且那个只言片语的聊天记录根本都算不上什么线索，也几乎没什么人相信他们，最后也是只能当作没事发生，就此收场了。”<br>“所以这个故事结束了？”<br>“差不多啊，这种都市传说本来就没头没尾的。”</p><p>——什么鬼，这故事……<br>“那你开那么严重的头，我以为故事有多少个连的鬼要登场。<br>“我看你们还是专专心心搞你们的轮滑吧，别整这些有的没的，我人生中宝贵的15分钟又被你浪费掉了。”<br>“我还不是怕你无聊～”<br>“谢谢哈，但是现在2020年了，我的手机可以无限畅游高速互联网哈。”</p><p>小李打完这一排字，准备把刚才开始就一直握在手上的耳机盒装进包里，小李稍稍转过身子，准备把一直夹在她和陌生人腿之间的斜挎包从侧面拽到前面来，小李甚至提前做好了因为拉拽动作而引起隔壁白眼的心理准备，但是小李移去视线，只看见不锈钢的地铁座椅。<br>——人呢？<br>不仅是隔壁这一个人，整排座椅只剩下小李一个人。<br>更确切地说，整个车厢，只剩下小李一个人，此时此刻正坐在椅子上。<br>——搞什么……？<br>面前，已经可以说是人声鼎沸了，各式各样的人们，男女老少，激烈地探讨着各种各样的事情，那个场景就好像是同学会上睽违四十年重逢的老同学们，想要把这四十年没能聊的天都聊个遍。<br>——这怎么回事……<br>小李开始有一些惊慌失措，她开始想从这个车厢逃出去。</p><p>“我跟你讲，我这节车厢真的好怪。<br>小李抬头望向就在身边的车厢门，透过玻璃门小李看见隔壁车厢门边斜对面的大叔正在看亨利·詹姆斯的《螺丝在拧紧》，那是小李爱看的小说，小李读完的时候跟小王说这小说绝不可能被好好拍成电影，小王说怎么不行，小李只好举了一个小王看过的《它》的例子来佐证她的观点，说这就像是德里镇的场，是没办法被具象化的，只有氛围能表达出来。<br>“算了我到了再跟你讲，我现在先换个车厢。<br>小李站起身，虽然聊天的人显然是过于投入，根本不可能注意到这里有个人几近是鬼鬼祟祟。<br>“你怎么不回？”<br>准备把手伸向把手之前，小李差点没抖着手给小王发去信息。点了好几次才终于点中发送键的小李，几乎是一步一步挪到了门边，然后把手伸向了把手。<br>——赶紧……！</p><p>突然，不知道是真的聊天的人们终于聊出了冲突，还是里面的人在推推搡搡，外围的一个人突然把小李撞了个踉跄，顺便也把小李好不容易搭上门把手的手给撞松开了。<br>小李抬起头，和眼前撞她的人四目相对。<br>那是一个很普通的大学生模样的男生，也就是小李上通识课的时候淹没在教室角落里的一百来个男生中的其中一个的程度。这个男生戴着很厚的眼镜，小李看不见他的眼睛，不过似乎可以隐隐约约感觉到很怪异的视线。<br>——是怪异吗？</p><p>这个男生忽然伸出手，一把搭在小李的肩上，把小李拉进人群。<br>“你来听听看这个人说的什么狗屁话……”</p><p><br><br><br><br></p><p>小王等了好几个小时，终于等到室友回到房间。室友今天在坐地铁要坐到底的客运站那边给初中生当家教，据说那个学生成绩差还不听话，虽然课时费给很多，但是室友说每次上完课都感觉老了十岁。<br>“你终于回来了，你再不回来我酒都要喝完了，<br>“你看，还有烧烤，都粘在一块儿了！”<br>——？你怎么还没到？<br>“给我留一口！”<br>“气吐了，下次绝不等你，我自己买来偷偷吃干净。”<br>——再不回来酒我自己喝了？<br>室友冲过来一把夺走小王手上的面筋。<br>“说起来上次借你的书，你啥时候看完啊，我可也是转租哈，我的债主图书馆晚还要交高利贷的哈！”<br>“就那个什么螺丝啊，你不要着急嘛，至于钱嘛……”<br>——嘿！你咋还不回消息了你，不会真的有痴汉吧！<br>“钱咋？你来付啊？”</p><p>“我们周姐哪儿缺这点儿钱呢？”小王露出谄媚的笑容。<br>——你撤回了一条消息 <em>重新编辑</em><br>——你撤回了一条消息 <em>重新编辑</em><br>——你撤回了一条消息 <em>重新编辑</em></p><br><p>-全文完-</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;“列车进站，请在黄色线后等待，排队上车，谢谢合作。”&lt;/p&gt;
&lt;p&gt;晚上十二点半的的地铁始发站根本看不见几个人，身处一号车厢位置的小李听见语音播报之后抬起头向另一方看，勉强可以看见几个下班应酬结束的醉汉摇摇晃晃的身影。小李从长椅上站起来，把刚刚在自动贩卖机买的饮料塞进包里，</summary>
      
    
    
    
    
    <category term="Chinese" scheme="https://blog.yuan-cong.com/tags/Chinese/"/>
    
    <category term="Work" scheme="https://blog.yuan-cong.com/tags/Work/"/>
    
  </entry>
  
  <entry>
    <title>文 | 烟灰</title>
    <link href="https://blog.yuan-cong.com/2020/06/30/%E6%96%87-%E7%83%9F%E7%81%B0/"/>
    <id>https://blog.yuan-cong.com/2020/06/30/%E6%96%87-%E7%83%9F%E7%81%B0/</id>
    <published>2020-06-30T06:27:18.000Z</published>
    <updated>2021-07-19T08:01:27.646Z</updated>
    
    <content type="html"><![CDATA[<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/193508450@N06/51320959271/in/dateposted-public/" title="Tobacco"><img src="https://live.staticflickr.com/65535/51320959271_c6d390d18b_b.jpg" width="1024" alt="Tobacco"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script><br><em>烟灰</em></p><p>小李最近学会了抽烟。</p><p>小王接到小李的电话吃了一惊，小李说自己想抽烟。<br>小王说：“你发什么神经，你复习完了没，怎么突然想抽烟？”</p><p>小李曾经也是很讨厌烟的人。<br>爸爸是资深烟民，所以小李也算是一个吸着二手烟长大的小孩。妈妈每天在家叫爸爸出去抽烟，但爸爸都置若罔闻，小李觉得自己绝对不要成为爸爸那样的人，小时候只是讨厌这种在别人面前抽烟的行为，后来久而久之，连带着香烟这种东西也一起讨厌了。</p><p>小李说：“还不就是太紧张，想吸点尼古丁压压惊。”<br>小王说：“你是打电话来通知我你要抽烟，还是你想问我你到底要不要抽烟？”<br>“就通知一下你。”<br>“行吧。”</p><p>小李的叛逆期好像来得很晚，大家初中的时候开始和爸妈吵架叛逆坏事都做干净了，小李在家和学校乖得跟蛋一样。其他人都说小李好乖，都没有忤逆父母云云。但是大家都开始变乖小孩了，读高中了上大学了，小李的叛逆期突然来了，高三的时候大家都忙着学习，小李在家忙着跟自己爸爸吵架，大四的时候大家都忙着找下家，小李在寝室睡觉，于是这一切的结局就是，膈应了别人也害惨了自己。<br>虽然这股叛逆的劲好像要过去了，但突然不知道哪里涌上来的抽烟欲望，也姑且把它算作叛逆的一部分吧。</p><p>小李说：“来，给你看看烟灰缸。”<br>“？！你肺已经蜂窝煤了吧？”</p><p>一开始抽得不是很厉害，但是越靠近考试的时候，就越抽越多了，经常在阳台上一坐就是一小时，一根接着一根，很快发展到了烟灰缸一天一倒的程度。被小王戏称老烟枪的时候，小李还开玩笑说这叫焦虑的可视化。</p><p>小李说：“很喜欢烟过了肺，再从嘴巴里出来的样子，感觉很成年人。”<br>小王说：“放屁，烟瘾就烟瘾，你写什么青春伤痛文学啊你。”<br>“去你妈的，成年人的快乐，你懂个锤子。”一边说着，一边把烟从嘴里吐出来。</p><p>白色的烟很浓，带着刺鼻的焦油味，又有一点薄荷的香，从嘴里慢慢地流泻出来。梅雨季节的风迅速吹散了它，细密的雨打消它往上攀升的念头，大概和雨点结合最后落到地面了吧。<br>小李喜欢看这样的画面，或者说抽烟有一半是为了看烟到底被流动的空气带到何处。</p><p>“啊，抽烟真好，我爱抽烟。”<br>小李词穷，说不出别的感叹词。<br>“要不要我给戒毒所打电话？”<br>“爬开！”</p><p>有一天晚上，小李做了一个梦。在梦里，分明是没有在抽烟的他，却一直从嘴里吐出烟圈，一个又一个烟圈在半空中互相交织，细细密密地缠绕在一起，像人的毛细血管在小李的眼前向两边无限延伸。突然这张烟组成的网突然消散，小李发现自己站在一片空地的中央，地面上铺满了烟灰，天上也在飘着烟灰，好像切尔诺贝利事件当晚的普里皮亚季城出现的“雪景”。小李在这片空地上走了好久，最后终于从自己床上睁开了眼睛。<br>好诡异的梦。小李一边洗掉自己脸上不知道是怎么蹭上的一条黑色污渍，一边回想梦的内容。</p><p>“我看你是抽烟抽疯了，做梦都在吐烟圈。”小王并不打算嘴下留情。<br>“你这嘴用502应该粘得上吧。咳，我又没抽多少，疯还不至于，谢谢关心。”<br>“你看你看，还咳嗽，抽抽抽，我看你得个呼吸道全家桶好去孟婆那儿喝汤，免得我以后见到你还要被迫二手烟。”<br>“（脏话）”</p><p>小李从那以后经常做这样的梦，明明没有抽烟却一直吐烟圈，在烟灰的世界里迷路，一摸头发手上都是又黑又臭的污渍。咳嗽也是完全没有好转的迹象，虽然没有像扁桃体发炎那样咳得上气不接下气，但是这样没来由的咳嗽终究还是令人在意。<br>是不是真的应该少抽一点，小李也经常这样想，但是说着只抽一根走上阳台，回来的时候又是满满一烟灰缸。</p><p>小王说：“你就少抽点呗，一天比一天少一点，这样也不行？”<br>小李说：“要那么容易大家都戒烟了。”<br>“算了算了never mind当我没说。”</p><p>奇怪的事情远远不只做梦和咳嗽这么简单。<br>小李经常在餐桌、洗漱台还有床上发现一些奇奇怪怪的白色或黑色的絮状物，本打算拿手去擦掉它，但是一摩擦，絮状物竟然顺着手动的方向变成一条黑色污渍。<br>烟灰。<br>小李百思不得其解，心想自己都在阳台上抽烟，烟味就算了，怎么会有烟灰在家里。</p><p>小李突然回想起来头一回做梦的那一天早上，自己也是从脸上洗掉了一条长长的黑色污斑。<br>小王说：“啊？脸上有烟灰？你做梦的时候不会在吃烟灰吧你！”<br>“谁在跟你开玩笑吗？你觉得是怎么回事？”<br>“我咋知道啊！就是不小心弄到的吧？你不要光顾着抽烟烟灰弄得一身都是……不要想那么多，赶紧来排位！”</p><p>那天晚上，小李迎来了怪异梦的大结局，小李在烟灰空地里吐出最后一个烟圈，突然所有的烟灰都被突然出现的狂风卷起来，冲着小李逼过来，好像要从耳朵鼻子嘴巴眼睛这样的地方冲进小李的体内。<br>小李惊醒了，拿起手机一看，半夜三点。<br>小李擦了擦汗，长出了一口气，心想应该不会再做这个梦了。<br>小李突然闻到了一股烟味。</p><p>后半夜果然没有再做这个梦了。</p><p><br><br></p><p>小李死了。<br>小王是好久之后才知道这个消息的。小李的家里对外说是交通事故去世的，后事也办得很低调。小王觉得奇怪，门都不出的人哪里有可能交通事故。有一次朋友聚会上，几个好朋友提起了小李去世的事情，虽然一时很感伤，但是小王也说了自己觉得交通事故跟小李很不搭。<br>“不过我也是听别人说，小李不是交通事故死的。<br>“去了葬礼的人说是死在家里的，是好几个月一直没交房租，房东觉得在意去开门才发现的，不知道已经去世多久了，不过尸体除了发青之外也没有什么奇怪的地方。”<br>“那不就说明是才去世没多久？”<br>“不对，是没办法判断。最奇怪的是，尸检的时候，据说脏器什么的都没有了…”<br>“啊？什么意思？”<br>“就是内脏都没有了……”<br>“不是说尸体除了发青没有其他奇怪的地方吗？”<br>“里面是其他东西。”<br>“是什么？”</p><p>“烟灰。”</p><br><p>-全文完-</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a data-flickr-embed=&quot;true&quot; href=&quot;https://www.flickr.com/photos/193508450@N06/51320959271/in/dateposted-public/&quot; title=&quot;Tobacco&quot;&gt;&lt;img src</summary>
      
    
    
    
    
    <category term="Chinese" scheme="https://blog.yuan-cong.com/tags/Chinese/"/>
    
    <category term="Work" scheme="https://blog.yuan-cong.com/tags/Work/"/>
    
  </entry>
  
  <entry>
    <title>笔记 | 游戏化实战</title>
    <link href="https://blog.yuan-cong.com/2020/05/24/%E6%B8%B8%E6%88%8F%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0/"/>
    <id>https://blog.yuan-cong.com/2020/05/24/%E6%B8%B8%E6%88%8F%E5%8C%96%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0/</id>
    <published>2020-05-24T08:42:20.000Z</published>
    <updated>2021-07-19T09:44:54.355Z</updated>
    
    <content type="html"><![CDATA[<p>游戏元素是手段，不是目的，游戏只是为了让玩家产生核心驱动力。<br><em>是一套专注于动机的设计系统。</em></p><h2 id="8大核心驱动力"><a href="#8大核心驱动力" class="headerlink" title="8大核心驱动力"></a>8大核心驱动力</h2><ol><li>史诗意义和使命感</li><li>进步与成就感</li><li>创意授权与反馈</li><li>所有权与拥有感</li><li>社交影响与关联性</li><li>稀缺性与渴望</li><li>未知性与好奇心</li><li>亏损与逃避心</li><li>(bonus) 感觉</li></ol><h2 id="1-史诗意义与使命感"><a href="#1-史诗意义与使命感" class="headerlink" title="1: 史诗意义与使命感"></a>1: 史诗意义与使命感</h2><p>几乎所有优秀的RPG游戏都一定会有这么一个为了“史诗意义和使命感”的设定，在这里我认为可以理解为“游戏背景”，使用户（玩家）为了达成某一个重要的目的或是完美的结局而进行游戏。</p><ol><li>《宝可梦》正统系列：培养强大的宝可梦阵容，打败反派团体以及成为联盟冠军。每一作宝可梦的故事主线几乎都是如此。不过当系列脍炙人口之后，“在下一作继续冒险”成为新的史诗意义，即为后面会提到的“情怀”；</li><li> 《牧场物语》系列：成为一个农场主以及一个小镇的居民，在那里展开新的生活。看起来并不是一个很强的动机，但我认为《牧场物语》系列最强的驱动力应该不是在这一个方面；</li><li>《火焰之纹章》系列：非常具有代入感的游戏设定，一般都有宏大的游戏背景。</li><li>《动物之森》：成为一个岛民代表，来负责整个岛上的岛民与役所交流的工作。</li></ol><h3 id="红包车的故事"><a href="#红包车的故事" class="headerlink" title="红包车的故事"></a>红包车的故事</h3><p>之前被我讲烂的红包车的故事。<br>红包车的使命感在于，所有的用户参与到偏远自行车的“救援”活动中来。这是这个活动的核心驱动力，也是他的目的。利用用户的善意，去唤起更多用户的善意。<br>这样的例子还有蚂蚁森林和Forest，以“种树”为概念，让越来越多的用户参与到活动或使用当中来。用户在消费，步行，或是专注的时候，不仅是为了这些目标本身，而是在为了一个造福地球或是全人类的计划作出贡献，这让他们更有动力。</p><h3 id="“情怀”"><a href="#“情怀”" class="headerlink" title="“情怀”"></a>“情怀”</h3><p>书中提到了“母校”，“篮球队情结”之类的故事，其实这样的故事在生活中随处可见。<br>例如，我的高中母校石室中学就是一个自带史诗光环的学校，学生的石室情结大多源自于对“全世界最古老的学校”这一事实的自豪感。因此，石室中学其实不需要校方做多大的努力，给多少钱来训练篮球队，或者是学科竞赛队伍（其实跟一般学生没有太大关系），甚至学校的领导团队每天被人诟病，就可以让学生有母校“情怀”。<br>我认为这种心情还可以用另一个词语来诠释，那就是“归属感”。好的动机设计，要给用户足够的归属感，让他体会到自己是这一个史诗任务的一份子，这个史诗背景没有他就不再成立。不过过度强调这一点也会适得其反，用户可能以为是传销组织。</p><h3 id="必须感觉真实"><a href="#必须感觉真实" class="headerlink" title="必须感觉真实"></a>必须感觉真实</h3><p>书里提到了“孝”。<br>这是一种需要身教的东西，意思就是说，每天言传其实是没效果的，即使每天跟小孩讲“孝”，但是并不体现在自己的行动上，那小孩是体会不到这个概念的，甚至还会有逆反心理。<br>真实需要怎么体现？<br>书里的地图软件（名字我忘了）使用了视觉和交互的方法，让用户体会到真实感。同时，概念本身需要是让人能信服的程度，所以概念的设计十分重要。所以我认为书里讲的真实和可信度可以看作是同一个要素。<br>概念的设计要本身符合逻辑，书里提到的“保持健康的垃圾食品”和“有益于环境的不可再生能源”之类的都是概念本身冲突的，这样的概念注定是失败的。<br><br></p><h2 id="2-进步与成就感"><a href="#2-进步与成就感" class="headerlink" title="2: 进步与成就感"></a>2: 进步与成就感</h2><h3 id="积分成就-象征系统"><a href="#积分成就-象征系统" class="headerlink" title="积分成就/象征系统"></a>积分成就/象征系统</h3><p>头脑风暴有成就系统的游戏：<br><strong>不直接体现</strong>在游戏里面的成就系统：Steam里的一些游戏，例如《返校》《还愿》等，成就系统嵌入在Steam平台里，不能在游戏中直接查看。<br><strong>直接体现</strong>的：</p><ol><li>《动物森友会》：有一些隐性的，例如岛上的布置到位之后评价到达五星，并获得金水壶，家装不断获得积分（隐形）来获得快乐家的高评级，挣钱还房贷等；以及一些显性的，里数系统、骆驼的兑换券等。</li><li>《宝可梦》：道馆徽章，地图点亮等，都能指示游戏的进展，作为一个象征系统。</li><li>《雷顿教授》：题目编号，基本可以看出游戏进展。</li><li>《牧场物语》：人物好感度是一个体现，特别是看见爱心变色的时候，会让玩家更有激情去提升这个角色的好感。同时这个部分也有一定的难度，需要判断对方喜欢什么，送礼物，以及掐点出现等等，同时也需要一些时间的积累，所以也有一定的挑战性。</li></ol><p>（类似）成就系统的软件/服务</p><ol><li>豆瓣：记录型的服务一般拥有一套成就系统，在早期的豆瓣中，比较明显的是“里程碑”，例如到达100，200，1000…这样的数据时会有一个里程碑，让自己以及其他人（社交性）看到进展，获得更多的动力；目前的豆瓣有正式加入徽章系统，将电影编辑成列表，观看完一个列表即获得相应的徽章。</li><li>Forest&amp;蚂蚁森林：捐树种树等等都有相应的可视化来激励用户。</li><li>一些积分系统：例如商家的促销活动，还有多少笔或是多少金额即可以获得XXX，一般在团体任务（即某时间段一共产生的订单量或是总金额）；最近在数据打榜之类的领域也有出现；</li></ol><h3 id="最容易实现的核心驱动力"><a href="#最容易实现的核心驱动力" class="headerlink" title="最容易实现的核心驱动力"></a>最容易实现的核心驱动力</h3><p><strong>为什么？</strong><br>我认为，不同于设计一个体系，或是一个社交逻辑，设计一个用于体现进步和成就的积分象征系统，最直观的理解应该就是一套数据的可视化，它可以是独立存在的，也可以是顺应背景故事顺理成章出现的，所以它的设计其实是很容易的。但是它困难的部分在于，在取得成就之前的这段过程，到底有多难，多具有挑战性，也就是规则的设定。书中提到说高尔夫的乐趣在于将球打进洞里，但是如果球员可以直接拿着球放进洞里，那将是非常无聊的运动，相反也成立，如果规则过于复杂，那么这项运动也会失去它的意义，人们将会望而却步，即使熟练之后可能十分有趣。</p><p><strong>核心驱动力来自于：</strong></p><ol><li>对复杂问题的自发的解决欲望</li><li>可行的解决方案</li></ol><h3 id="让用户觉得自己聪明"><a href="#让用户觉得自己聪明" class="headerlink" title="让用户觉得自己聪明"></a>让用户觉得自己聪明</h3><p>这一点很重要，如果你事无巨细告诉用户，那么用户只会觉得过于啰嗦以及你在藐视他的智商。从我个人的体验出发，如果将一些比较浅显的步骤或是方法省略，或是说将一些步骤交给用户来完成，用户会觉得首先，自己是能够发挥聪明才智的，第二，自己有被充分地信任，当然，我觉得这一点应该慢慢重复地研究。<br>以上这一点，从可用性的角度来讲，是完全背道而驰的，可用性讲求的是在可行的范围内将能够替用户完成的悉数完成，让用户来做最少以及最简单的步骤。</p><h3 id="以人为本-or-以用户为中心？"><a href="#以人为本-or-以用户为中心？" class="headerlink" title="以人为本 or 以用户为中心？"></a>以人为本 or 以用户为中心？</h3><p><strong>我觉得这两个概念太重要了，超级着重符号</strong></p><p><strong>以人为本</strong>的设计是什么？<br>考虑到人最本质需求的设计，也就是回归到“人为什么要做这件事情”上面来，也就是说，这样的设计方法，需要我们去找人的核心动机，或者是为用户创造动机。举个例子，运动的第一层动机可能是减肥，增肌，或者是变健康，深层动机可能有让自己变好看，为了追男女朋友等等，有些人这样的核心动机足够打败他们的怠惰心理，于是他们坚持下来了，成功坚持了运动；但是有些人的核心驱动力不足以打败他们的怠惰心理，于是设计师需要帮他们寻找更多的动机，可能是用设计方法为他们创造新的动机。例如消费冲动暂且不能打败理智的时候，商家的满减活动可以让顾客立马再冲进货架。<br>这样的设计显然不是易用的，因为它使用户付出了更多的时间金钱体力，但是它是考虑和照顾了用户核心驱动力的设计。</p><p><strong>以用户为中心</strong>的设计又如何？<br>以用户为中心的设计可以用一个词来概括，就是“好用”。它是帮用户省下上述时间金钱体力的设计。也就是说，“帮用户省事”的设计可以叫做是以用户为中心的设计。<br>但是这两者如何达到平衡需要具体情况具体分析。</p><h3 id="排名的设计"><a href="#排名的设计" class="headerlink" title="排名的设计"></a>排名的设计</h3><p>让用户觉得<strong>通过自己努力是可以达到</strong>的。<br>这一点很重要，如果一开始来到一个已经开服了三年的游戏，而排名不是按照段位而是不清空的积分制，那么用户会觉得自己达到第一或是上位圈是永远也不可能的事情。局部排名可以让用户看见自己分数相近的其他用户，而这些用户是直接跟自己的排名相关的。<br>举个例子，高三的时候我位于全年级的200名左右，但是最上位圈1-5名一般比我的总分高出近100分，那么如果我以他们为目标努力，放弃只是分分钟的事情，但是如果我将年级排名或是班级排名中我附近包括我的5名同学截取出来，以超越上面两个和不被下面两个超越为目标，那么实现就变得容得多了。<br>同样的，我把我关系好的（好友圈）的几个同学截取出来，在这样一个小范围内比较，也自然会与跟陌生人比较的心理状态是不同的。<br><br></p><h2 id="3-创意授权与反馈"><a href="#3-创意授权与反馈" class="headerlink" title="3: 创意授权与反馈"></a>3: 创意授权与反馈</h2><p>我认为创意授权和反馈是一个不太好理解和解释的概念。可以理解为用提供多种多样的“玩法”来给玩家更高的自由度和选择权，然后用反馈机制来告诉玩家这样的选择的结果。但是难以理解的是，通过创意授权来刺激用户的创造力的部分，这样一来，吸引用户继续游戏的动机就不再是游戏设计师设计出来的全新的游戏内容，而是玩家自己的想法。</p><h3 id="获胜途径的唯一标准？"><a href="#获胜途径的唯一标准？" class="headerlink" title="获胜途径的唯一标准？"></a>获胜途径的唯一标准？</h3><p>就像是学生，中国国内的教育体系（当然也是无奈之举），普遍倾向于引导学生达成“只有高考才能出人头地”的认识，那么这就迫使学生通过同样的途径去达成高考或是说远一点，人生这个“游戏结局”，撇开这个目的本身存在的第一大核心驱动力（史诗意义和使命感）的问题，这剥夺了学生的自由度和选择权，学生没有办法做出自己的选择时，自然会丧失耐心和动力，我认为这也是为什么说教育体制让很多学生错失了个性发展的机会和时间的很大的原因。</p><p><strong>什么才叫获胜？</strong><br>游戏里会有这样的设定，例如“打败大boss”，“成为冠军”，“拯救世界”，“解决所有的谜题”等等，但是也有游戏不会有这样的设定，或者会有相对较弱的主线剧情，以及一个临时结局（这是我编的名词，我不知道有没有这样的名词），例如《动物之森》，邀请到KK来开演唱会之后会有字幕出现，但其实真正自由的岛上生活才正式开始；《牧场物语 无暇人生》（PSP）（我记不太清了）第一年会有一条比较强的主线剧情，但第一年之后玩家依旧可以按照自己的想法继续探索和游戏，以及完成其他支线剧情，这样的结局一般是比较弱的，是一个形式上的结局，或者更恰当地，是一个里程碑，相比“结束”的语义，更接近一个玩家解锁所有游戏要素，现在可以随心所欲进行游戏的“通知”。<br>这样的里程碑的完成方法一般是比较固定的，比如达成“完成20次对局”，“将房子扩建”，“将居民的好感度达到200”等的任务，但是完成这些任务的方法或是步调是用户自己决定的，我可以卖鱼卖虫，也可以炒大头菜达到房子扩建的目的，我可以肝，两天就完成这个任务，我也可以第20天再凑齐这个钱。<br>这样一来，通往“获胜”的路径有很多条，同时，“获胜”可能有很多种，但一般游戏会有一个趋于统一的评价，虽然如此，这样的游戏会相对弱化这样的评价，让玩家有更大的自由和选择权。</p><h3 id="元素周期表-vs-游戏卡牌？"><a href="#元素周期表-vs-游戏卡牌？" class="headerlink" title="元素周期表 vs 游戏卡牌？"></a>元素周期表 vs 游戏卡牌？</h3><p>本质是一样的，元素周期表可能还比卡牌数量和性质更少一些，但小孩更喜欢去研究卡牌，甚至不惜花上几个小时时间去研究相生相克的关系，以此来战胜其他玩家（可能是他的朋友和同学），这是为什么？我们倾向于告诉小孩，现在学元素周期表是为了你的未来你的前途等等，但是这样的“史诗意义”对小孩不具有真实感，真实感是一个产生共情的重要要素，小孩无法在短期内得到自己好好学或者不学元素周期表的结果，在这样无法对自己的未来前途等产生共情的情况下，当然不比短期就能检测自己的新策略是否有效果的卡牌游戏来得更有趣。<br>如果把元素周期表也变成卡牌游戏？我开玩笑的。<br><br></p><h2 id="4-所有权与拥有感"><a href="#4-所有权与拥有感" class="headerlink" title="4: 所有权与拥有感"></a>4: 所有权与拥有感</h2><h3 id="数字变成口袋里的钱，我可以立刻变成数学天才"><a href="#数字变成口袋里的钱，我可以立刻变成数学天才" class="headerlink" title="数字变成口袋里的钱，我可以立刻变成数学天才"></a>数字变成口袋里的钱，我可以立刻变成数学天才</h3><p>数学书上写的1000，当他不代表任何意义的时候，看书的人不觉得它减去500或者去积个分跟自己有什么关系。但是如果这1000变成自己拥有的东西，那么或多或少会因为共情关系产生一点兴趣。<br>大学学概率论的时候不会觉得什么模型又怎么样了，但是自己经商或者炒股的时候，这个或者那个模型，会变成自己的分析工具，当然，那些无意义的数字变成了自己的拥有物，但是其实更重要的一点是这些数学知识变成了为自己的动机服务的工具。<br>所以我认为，虽然这句话跟所有权和拥有感有关系，但这句话有道理的原因并不主要是这个。</p><h3 id="收集癖"><a href="#收集癖" class="headerlink" title="收集癖"></a>收集癖</h3><p>动森的论坛里经常可以看见这个词，我认为这有一部分源自于人们或多或少有的强迫症。<br>书中举的例子是“一张邮票要放在一整套里面才有意义”，的确，一张邮票或者是差一张的一整套都不算是完整的，可是我觉得这一点和动森里的家具收集有一定的差别。一张邮票是属于一套邮票的一个部分，而一张邮票是不值钱的，也不具备任何的收藏价值（除非它非常精美），但是它和其余所有的部分合在一起成为了一个完整的collection，那么它将瞬间价值不菲，简而言之，一件单品，如果它从整体中取出，将会使整体和它都无法使用，或是价值大跌，那么这样的收集，我认为这个是书中所讲的收集欲望。<br>但是，如果这一个单品，本身在不在整体内都不影响它的价值和使用的话，我觉得不够成普通的收集概念。我们也许可以经常看见有人发帖想要或者是补齐某某系列的全套家具，但是其实这样的收集我认为其大部分的核心动机不是“所有权与拥有感”，而是“进步与成就感”和其他的<strong>黑帽动机</strong>，源自于稀缺感带来的不安，这是因为收集之后的家具单品或者是这一整套并不会有多大的价值浮动，也不会给玩家带来情感安慰，玩家在收集之后就会遗忘这一套家具，继而转战其他的家具系列。<br>所以收集癖也分成很多种情况，有些重点在收集，有些只是癖在作祟。如何使玩家在集齐全套之后感觉价值提升以及情感安慰，而不是一件落着，好去做下一件事情，是我觉得应该考虑的问题。</p><h3 id="宠物石头？？"><a href="#宠物石头？？" class="headerlink" title="宠物石头？？"></a>宠物石头？？</h3><p>其实真的是一个匪夷所思的东西，如果现在去询问那些当年买过宠物石头并精心呵护的人，现在应该有一半觉得自己曾经是疯子吧（我猜的）。<br>但是其实它风靡的原因并不难理解，一个几乎零抚养成本的“宠物”，这个概念真的很吸引人，所以冲动使人们将它们带回家，并且开始了一段时间的自我催眠。<br>“拥有”使人们爱护，所以即使是石头，也能获得其主人的爱，更何况这是一个“宠物”石头，所以平时那些因为没有时间照顾宠物而不能买宠物的人借此机会体验了有宠物的生活。概念非常重要，如果他推出的时候就是单纯的卖石头，那我想他一个也卖不出去，但是这卖的是宠物，这不是精美的包装盒装起来的石头，而是不需要你照料他也不会死的宠物，本质是同一个东西，但在消费者看来有天壤之别。<br>它的风靡还有另外的原因，即使这个概念推出了，但是街上只有一个人这么养着石头，那我觉得不仅是街上的其他人，他自己可能也觉得自己很像个疯子。但是街上所有人都在养石头，只有我一个人不养，那我好像和这个社会格格不入。<br>群体性心理对这个养石头的行为有很大的影响。养石头本身是超出常识范围的行为，但是既然周围的人都在养，那我也不用不好意思养石头，毕竟大家都有嘛。所以那些心理防线其实是大家一起攻破的。<br>但是确实，宠物石头没有反馈机制，狗会摇尾巴，但石头永远都只有沉默，所以逐渐发现给石头洗澡喂食讲话这些行为本质的冷静下来的消费者，会最后选择放弃这个完美宠物。<br>最后加一句，好的概念，真的可以让人心甘情愿买单。</p><h3 id="拓麻歌子"><a href="#拓麻歌子" class="headerlink" title="拓麻歌子"></a>拓麻歌子</h3><p>拓麻歌子在我小学的时候也风靡一时，几乎所有人都有一台，班主任没收都收不过来。<br>拓麻歌子其实和石头是一个道理，只是拓麻歌子少了一些心里的坎（毕竟是真的养的电子宠物），以及加入了一些反馈机制，至少你给他洗澡的时候你知道它心情怎样。<br>但是电子宠物毕竟也只是代码，玩家即使可以养凤凰养恐龙，它们也只是简单的代码，当它的反应开始出现重复，玩家逐渐丧失和它们的共情力的时候，玩家也会选择离开。</p><h3 id="禀赋效应"><a href="#禀赋效应" class="headerlink" title="禀赋效应"></a>禀赋效应</h3><p>这个重点是，拥有者可能甚至还没有拥有这个物品。<br>当有人来告诉说，上面那个水果篮给你了，等会课上完了你就拿走吧，那么我就会一直盯着它，因为我相信这个水果篮已经是我的了，哪怕是有人经过，我都会很紧张他会不会顺个苹果走。但是如果没人跟我讲这句话，我可能根本不会关心那里还有一个水果篮。<br>有一个真实的故事，我在动森里种了很多果树，但其实我平时根本不会去摘，但有一天我有一个好友上我的岛，问我可不可以摘一些果子回去种，我同意之后就去忙自己的事情去了，回来发现整个岛上的果子都没了，我顿时气得火冒三丈，虽然没有去骂他，但是还是一个人气了很久。这就是拥有感的一个很典型的例子，也和禀赋效应沾边，因为果子在树上，人人都可以来摘，只要不在我的包里其实也不见得就是我的了，但毕竟是我的岛，那么岛上的东西顺理成章地有理由相信就是我的东西，所以当我相信这些都是我的东西的时候，我就会更加看重它。相反，如果只是资源岛上的苹果被人摇走了，我想我应该不会有任何反应。</p><h3 id="自己的身份"><a href="#自己的身份" class="headerlink" title="自己的身份"></a>自己的身份</h3><p>这个真的很妙，其实有一点点道德绑架的感觉。<br>人们追求行为的一致性，什么意思呢？如果我今天在路上被拦下来捐了款，那我明天被拦下来大概率也会捐款，因为我不想被看成是一个对慈善三分钟热度的人。再举个例子，如果我今天出去操场跑步遇到了熟人，那么我大概率会接连好几天都出去跑步，因为我不想被人看成是三天打鱼两天晒网的人。<br>人们保持同样的行为，以此来展示自己的价值观。<br>那么反过来，利用人的价值观，我们可以让玩家保持同样的行为。</p><h4 id="重要的再写一下"><a href="#重要的再写一下" class="headerlink" title="重要的再写一下"></a>重要的再写一下</h4><p>书写（承诺）让人们更坚定自己的决定<br><strong>从零构建</strong>：相比昂贵的高端家具，人们更加珍视自己组装的宜家家具<br><strong>收藏集</strong>：最强大最有效的方法 -&gt; 核心驱动力8: 亏损和逃避心也起到很大作用<br>人们喜欢自己感到熟悉的东西 -&gt; 安全感和渴望<br>向用户提供更加定制化的内容，即使并没有真正的定制化。<br><br></p><h2 id="5-社交影响与关联性"><a href="#5-社交影响与关联性" class="headerlink" title="5: 社交影响与关联性"></a>5: 社交影响与关联性</h2><h3 id="社会规范"><a href="#社会规范" class="headerlink" title="社会规范"></a>社会规范</h3><p>读了书之后，我认为这个规范的语义可能不同于中文中常见的规范二字，通俗一点讲，这个“社会规范”应该指的是“这个社会上大家都在做的事”，其实利用的就是从众心理。当一个人融入集体当中，他将在一定程度上失去独立思考的能力，认为别人都在做的一定没错，从而逐渐形成这样的“社会规范”。例如，中国式过马路，这就是一个社会规范，但他并不是一个“规范”的行为。<br>例如《火焰之纹章：风花雪月》，在自由活动时会显示其他的玩家采取了怎样的行动，初级玩家或是懒得想玩家会跟随大部分玩家的选择来进行游戏，这就是一种社会规范，当然你也可以进行其他的行动，设计者所做的就是告诉你其他玩家做了什么而已。</p><h3 id="“羡慕”"><a href="#“羡慕”" class="headerlink" title="“羡慕”"></a>“羡慕”</h3><p>我想到的第一个就是王者荣耀的限定皮肤。首先因为它们足够稀缺，然后拥有的人可以让周围的人足够眼红，这就是羡慕的来源。当年我们一群人因为想得到霸王别姬的皮肤在那边每天快死了，看见游戏里有人用都恨不得把那人从屏幕里面拽出来。通常我认为，这样的羡慕，甚至可能已经发展成嫉妒的情绪，可能会有两种终极结果，第一种是得到这个东西，然后心满意足，第二种是真的没办法得到这东西，然后干脆把这东西从脑海里面删掉，就是远离跟它有关的所有事物，眼不见心不烦。这两种对应的情景分别是，第一种，有一天突然能买到这个皮肤了，然后赶紧买下来，去眼红别人，第二种，实在是没办法，天美做绝了，就是拍板官宣了，永世不得再贩卖霸王别姬皮肤，那我们可能就大骂天美没有心，然后愤愤退游。<br>如果有用户反映，“啊真的好想要这个皮肤，想得睡不着吃不下，卖一下好不好就卖一个小时”，这时如果天美就“哦，好”，然后开始卖，那我觉得爱这个皮肤的人应该就会少一半，在这样的情况下，这个限定皮肤失去了它的稀缺性。所以从根本上来说，社交影响应该是和稀缺性紧密相关的。<br>当然，我们最后还是如愿获得了皮肤，在某个大年夜，它返场了，和另外几个昂贵的新皮肤一起上架，夺走了大家还热乎的压岁钱。“返场”这个词真的很隆重，具有很强的仪式感，让人想焚香沐浴充好点券等待这一刻的来临，所以让“我要获得皮肤”这个目的有了一抹史诗色彩。把摆在货架上的东西变成了你辛苦等待的奖励，虽然是你自己花钱拿下来的。<br>但是天美做的很妙的地方是，他没有断玩家的路，他时不时投个票，过年过节返个场，用户觉得有希望，自己喜欢的皮肤说不定哪天也会返场，所以才有耐心一直等下去（但是这个等待的周期又不能太长，同时也需要各种各样的营销来吊胃口）。所以，在这里，天美<strong>提供了一条真实的路径让用户拥有这些羡慕的东西</strong>。</p><h3 id="师徒关系"><a href="#师徒关系" class="headerlink" title="师徒关系"></a>师徒关系</h3><p>我个人打游戏比较封闭，也没怎么跟人交流过，虽然在梦幻西游里面系统随机分配过一个师父，但也没交流过。但是我认为一个师徒系统的目的，和书里讲的一样，第一点，让新手用户，或者是低级用户，知道高级用户，熟练用户在做什么，以及怎么操作的，第二点，帮助新手解决问题，实现双赢。<br>此处有一个很重要的词，叫做<em>“身份津贴”</em>，这可以是任何东西，甚至是“愉快的心情”，只要是能够对“师父”这一身份产生认同的，就是身份津贴。<br>师徒关系在让新手感到史诗意义这一目的上也有相当的辅助作用。</p><h3 id="助攻"><a href="#助攻" class="headerlink" title="助攻"></a>助攻</h3><p>想象这样一个场景，在王者荣耀里面，不再有助攻这一个指标，当然助攻之后也不再有钱分，然后有这样一局，有一个一打五的大佬大杀特杀，此时，队友的其他四个人还会想要去参团吗？这就是moba游戏虽然关心个人战绩，但是同时也能够顾虑到团队合作的方法，竞争同时也在合作。</p><h3 id="奖杯架"><a href="#奖杯架" class="headerlink" title="奖杯架"></a>奖杯架</h3><p>一个陈列室的概念模型，是个人成就的橱窗，即使自己不去主动炫耀，访问个人主页的用户依旧可以直接看到这些奖杯。相比起直接分享到朋友圈或者发信息告诉别人这样的行为，一个奖杯架显然更隐晦一点。</p><h3 id="社交刺激"><a href="#社交刺激" class="headerlink" title="社交刺激"></a>社交刺激</h3><p>点赞或是在看等等，这些都是最小限度的社交行为。用户不需要表达什么情绪或意见，有一种“已阅”的感觉，像是维持人际关系的最小限度的努力。这样的方法可以用最小的成本，让用户完成社交行动，以及让用户得到“别人的关注”。</p><h3 id="病毒营销"><a href="#病毒营销" class="headerlink" title="病毒营销"></a>病毒营销</h3><p>团队任务中会用到这样的方法，其中一个很著名的例子就是团购，人们看广告可能不如亲朋好友推荐来得有效果，而团购正好是利用了这一点，用户想要获得优惠价，可以，那就把我们的产品推荐给其他人，并让其他人来加入用户的队伍中来一起获得这个优惠。这样一来，商家可能损失了一定的利润，但是却无限扩张了他们的业务范围。<br><br></p><h2 id="6-稀缺性与渴望"><a href="#6-稀缺性与渴望" class="headerlink" title="6: 稀缺性与渴望"></a>6: 稀缺性与渴望</h2><p>稀缺性我认为是一个很好理解的点，结合“感知价值”这一个关键词，即越不容易获得的东西，人们的关注度越高。所以相对来说比较难的是如何让用户感到稀缺。</p><h3 id="悬挂技巧"><a href="#悬挂技巧" class="headerlink" title="悬挂技巧"></a>悬挂技巧</h3><p>为了节省时间，人们愿意付出其他成本，例如金钱，或是进行分享给好友等操作。<br>在上一章的笔记中有提到关于王者荣耀的皮肤是如何利用悬挂技巧的，也提到如果不能好好控制稀缺感，那将会招致用户的逃避心，从而导致用户的流失。</p><h3 id="锚式并列"><a href="#锚式并列" class="headerlink" title="锚式并列"></a>锚式并列</h3><p>和悬挂技巧可以并列使用的技巧。<br>悬挂技巧告诉用户或玩家，只要付出一定时间的努力，就可以获得想要的结果或是物品。但是锚式并列提供给用户更多的选择，也就是选择付出其他的成本，例如金钱成本，社交成本等等来达成目的。像一般的抽卡游戏，我可以每天肝游戏攒够一个十连，我也可以通过氪金直接立马获得一个十连。<br>对于FOREST这样的app来说，显然是不可能让用户直接买树种在地上的，不过它利用了人们不能忍受瑕疵的心理，提出了可以用氪金来解决枯树的方案。</p><h3 id="折磨休息与约定动机"><a href="#折磨休息与约定动机" class="headerlink" title="折磨休息与约定动机"></a>折磨休息与约定动机</h3><p>光看概念其实我觉得比较难以理解，但是结合手游的能量系统就很好理解了，虽然是强制让玩家休息了，但是每一分每一秒都是折磨，而且玩家会在明明知道还有一两个小时才能继续游戏的时候去查看剩余时间。更明显的折磨休息是电视剧更新，明明知道周四才会更新，但观众还是会在周三晚上去检查有没有出现新的资源。<br>这之后就是约定动机了。像是游戏内期间活动，“期间限定”物品的获得，这些都是围绕时间展开的项目。像是产品和用户约定好的，在指定时间完成指定的内容。<br><br></p><h2 id="7-未知性与好奇心"><a href="#7-未知性与好奇心" class="headerlink" title="7: 未知性与好奇心"></a>7: 未知性与好奇心</h2><p>相对于知道结局的过程，人们更享受处于未知环境之中。<br>一个很极端的例子，鬼屋。人们知道自己在里面一定会被吓，但是仍旧趋之若鹜，因为他们想知道里面的东西到底有多吓人。于是世界上有了各种各样的知名鬼屋。例如位于富士山脚下的慈急综合医院，是世界上最长的鬼屋。一般的鬼屋之拥有一条路，也就是说，最多三次，玩家将记得里面的构造和吓人的点，但慈急综合医院不同，每次进去都会是完全不同的构造，也就是说，每次都是未知的，这也就吸引了人们进去一次两次三次甚至是十次以上。</p><h3 id="斯纳金箱"><a href="#斯纳金箱" class="headerlink" title="斯纳金箱"></a>斯纳金箱</h3><p>人们会一直去操作，试图试探下一个结果是什么。这其实违背了惊喜的初衷，造成的是一种强迫行为。最后触发的是的消极心理因素。</p><h3 id="幸运日"><a href="#幸运日" class="headerlink" title="幸运日"></a>幸运日</h3><p>今天运气不错。<br>例如《动物森友会》中大头菜的价格。一次偶然的大头菜价格上涨，其实会在无形当中让玩家玩得更久，即使在玩家觉得“没关系我也不需要大头菜卖得多贵”的时候。<br>这样的激励会让用户觉得，好，那我再留一下。</p><h3 id="激励分享"><a href="#激励分享" class="headerlink" title="激励分享"></a>激励分享</h3><p>还是《动物森友会》的例子，如果一名玩家进入商店，看见自己家大头菜今日价格是640，那他大概会告诉所有的亲朋好友，让他们来自己岛上卖大头菜，他甚至会在论坛、推特等SNS发帖，邀请并不认识的网友前来。这就是激励分享。<br><br></p><h2 id="8-亏损与逃避心"><a href="#8-亏损与逃避心" class="headerlink" title="8: 亏损与逃避心"></a>8: 亏损与逃避心</h2><p>我觉得这一章内容真的很好理解，所以我随便写一下我自己的想法。<br>亏损与逃避心主要是讲到人靠本能在避免失去东西，也就是亏损。这一种本能会涉及到很多种心理，譬如说书中讲到的侥幸心。人的心态很奇怪，尚且还不是自己的东西，但是一旦认定了是自己的，就会开始害怕失去它了。<br>第一个例子，保研。我其实是从大一开始就一直想出国的，但是当我最后发现有机会拿到保研名额的时候，反而开始纠结自己到底是保研还是出国了。虽然我觉得可能性质有点不同，但其实很有力地说明了避免亏损的心理。人是很难做到断舍离的，因为人什么都想要，所以网络上突然出现的优惠券完全可能让完全没有消费计划的人活生生地花掉优惠券面额的十倍金钱，人们觉得优惠券不用白不用，不用岂不是自己亏了。但是很难有理性的消费者想到在遇到这张优惠券之前自己根本就没有消费计划。<br>第二个例子，手机游戏。手机游戏其实是一个巨坑，尤其当用户在里面花掉巨额金钱或是用户在里面花掉的时间非常多的时候，这时候用户是完全无法摆脱这个游戏的，因为里面的一切都是自己的沉没成本。例如，我在王者荣耀中花了很多钱买皮肤和英雄，虽然有些我根本不用，而且后来发现我其实根本就不太爱玩这个游戏，所以很多次都想戒掉这个游戏，但是都失败，因为自己舍不得这些沉没成本。后来买皮肤买英雄其实已经变成是一种强迫行为，后来当然通过彻底卸载游戏成功了，不过代价是想到自己花的钱依旧会觉得可惜。<br>第三个例子，普遍心理状态。很多人不想做一些事情的原因其实是害怕失败的结果，因为人们不想忙活半天最后还不得不承认自己是白忙活。所以这一个特性造成了很多人的怠惰心理。<br><br></p><p>-全文完-</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;游戏元素是手段，不是目的，游戏只是为了让玩家产生核心驱动力。&lt;br&gt;&lt;em&gt;是一套专注于动机的设计系统。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;8大核心驱动力&quot;&gt;&lt;a href=&quot;#8大核心驱动力&quot; class=&quot;headerlink&quot; title=&quot;8大核心驱动力&quot;&gt;&lt;/a&gt;</summary>
      
    
    
    
    
    <category term="Chinese" scheme="https://blog.yuan-cong.com/tags/Chinese/"/>
    
    <category term="Note" scheme="https://blog.yuan-cong.com/tags/Note/"/>
    
  </entry>
  
  <entry>
    <title>译 | 首先记住这些吧！《蜡笔小新》系列入门专栏</title>
    <link href="https://blog.yuan-cong.com/2020/05/24/%E8%AF%91-%E9%A6%96%E5%85%88%E8%AE%B0%E4%BD%8F%E8%BF%99%E4%BA%9B%E5%90%A7%EF%BC%81%E3%80%8A%E8%9C%A1%E7%AC%94%E5%B0%8F%E6%96%B0%E3%80%8B%E7%B3%BB%E5%88%97%E5%85%A5%E9%97%A8%E4%B8%93%E6%A0%8F/"/>
    <id>https://blog.yuan-cong.com/2020/05/24/%E8%AF%91-%E9%A6%96%E5%85%88%E8%AE%B0%E4%BD%8F%E8%BF%99%E4%BA%9B%E5%90%A7%EF%BC%81%E3%80%8A%E8%9C%A1%E7%AC%94%E5%B0%8F%E6%96%B0%E3%80%8B%E7%B3%BB%E5%88%97%E5%85%A5%E9%97%A8%E4%B8%93%E6%A0%8F/</id>
    <published>2020-05-23T19:38:02.000Z</published>
    <updated>2021-07-19T08:01:17.727Z</updated>
    
    <content type="html"><![CDATA[<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/193508450@N06/51320785154/in/dateposted-public/" title="shinchan"><img src="https://live.staticflickr.com/65535/51320785154_2a2c5ebb0b_b.jpg" width="724" alt="shinchan"></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script><br><em>ケトル Vol. 53 April 2020</em></p><p>文/小山田裕哉</p><p>30年的历史中有太多的名场面和人物！作为系列的入门篇，在这里介绍一些出场角色和入门杂学。</p><h2 id="保卫春日部的和平！个性丰富的“春日部防卫队”成员"><a href="#保卫春日部的和平！个性丰富的“春日部防卫队”成员" class="headerlink" title="保卫春日部的和平！个性丰富的“春日部防卫队”成员"></a>保卫春日部的和平！个性丰富的“春日部防卫队”成员</h2><p>从野原新之助开始，到风间澈、佐藤正男、樱田妮妮、阿呆这五个好朋友组成的“春日部防卫队”，原作中首次出场在第11卷，动画则在1995年5月1日播送的《春日部防卫队！》中首次登场。<br>自称是队长的风间是成员中唯一一个上补习班、会说英语、会读很难的汉字的让人觉得不像是5岁小孩的人。但是其实是有着超级恋母情结，在没人看到的时候会找妈妈要抱抱的小孩。不仅如此，他还是会偷偷沉迷于美少女动画角色的cosplay的少女动画的狂热粉。<br>一丝不苟的正男，是一个丁点大的事情也会哭的胆怯小孩。但是不知道是不是因为后坐力，当他的紧张感到达顶端的时候就会有不为人知的一面出现，变成一个狂野男子。在剧场版《大人帝国的反击》中，为了从大人的追捕中逃脱，大家驾驶起了幼儿园的大巴车，正男在摸到方向盘的瞬间，大吼一声“冲吧，宝贝！”，随即开始暴走。<br>唯一的女生妮妮，在最开始的时候是一个哭包角色。但是不知道是不是在新之助身边被锻炼太久，现在变得比谁都要强了。她的兴趣爱好“真实过家家”，经常以出轨、不伦或是婆媳关系为主题，而队员们一直是被妮妮强行拉来参加的对象。因为有生气就揍兔子玩偶的习惯，所以当幼儿园来了真的兔子的时候，妮妮也想过揍它们。<br>接着，是最为神秘的阿呆。虽然看起来一直都是流着鼻涕一副发呆的样子，但是阿呆其实运动神经发达（接力的时候轻松获得幼儿园优胜）、只是看着园长开车就记住了大巴车怎么开（而且是手动挡）等等，藏着各种各样令人意外的才能。阿呆即使在系列最开始就登场了，但是本名、住址、家人的样子等等目前我们都还不得而知。<br>这样的五个幼儿园小孩组成的春日部防卫队，虽然平时的活动是以在幼儿园的班主任吉永老师家里面玩为主，但真有什么事发生的时候，为了保卫春日部的和平，大家又会相互鼓励踏上冒险的征程。那个时候的口号当然就是“春日部防卫队，出击！”</p><h2 id="为什么春日部是这个系列的舞台？"><a href="#为什么春日部是这个系列的舞台？" class="headerlink" title="为什么春日部是这个系列的舞台？"></a>为什么春日部是这个系列的舞台？</h2><p>野原一家决定住在埼玉县春日部市（漫画原作用平假名かすかべ）是新之助出生之后的事情。那时广治和美冴从新婚时代开始一直住的公寓因为新之助的出生而显得过于狭窄了，虽然两人一直在找带庭院的独户房子，但因为预算的关系一直没找到合适的。那时，在偶然进入的一家不动产店里被人推荐了在春日部市被卖剩下来的房子（原作第45卷）。<br>而春日部市成为《蜡笔小新》故事的舞台的原因，据说是因为作者臼井仪人老师曾在那里工作，成为漫画家之后也曾经住在那里。本来臼井老师就是一个很擅长将身边的故事画进漫画的漫画家，他的漫画出道作，以超市为舞台的《不良百货商场》也是从他成为漫画家之前在广告公司工作，曾经为超市设计制作过物料的经验中诞生的。<br>据曾经负责过原作漫画的初代编辑，双叶社的林克之先生所说，之所以野原一家的构成是“核家庭”（由父母和未婚子女构成的小家庭），是因为臼井老师的家庭也是这样的构造。“当然反映小孩教育是一方面。漫画比起反映脑子里所想的东西，反映出的作者为人这一方面更有趣。”<br>就像广治和美冴决定住在春日部的时候，关于春日部市的魅力说到的“这个地方有一种不可思议的令人怀念的感觉”，“感觉在这里新之助能够健康长大”，到目前为止，春日部市也依旧在通过《蜡笔小新》在向全国，乃至全世界传播它的魅力。<br>2004年，作为春日部市市制50周年活动的一环，野原一家以地址“春日部市双叶町904”正式作为住民在春日部市进行了住民注册。虽然是虚构的地址，但是双叶社解释说“904”是由“蜡笔”的日语发音谐音而来的，所以其实是一个包含了对小新的爱的地名。春日部市里有很多与作品相关联的地点，如果是粉丝的话请一定去拜访。</p><h2 id="野原家并不是一直住在那里的"><a href="#野原家并不是一直住在那里的" class="headerlink" title="野原家并不是一直住在那里的"></a>野原家并不是一直住在那里的</h2><p>野原家的住所，就是位于春日部市的一栋附带庭院的独栋建筑。野原家贷了35年的款买下的4DK住宅。对于这个系列的熟人来说可能是“这还用讲”的话题，但是这栋房子在贷款还剩30多年的时候，因为煤气爆炸曾经一度烧得干干净净。美冴因为被蟑螂吓到而忘记关煤气，这时新之助在屋子里用点火棒点火造成了这一事故（原作29卷）。用火灾保险进行灾后重建期间，野原一家暂住在名叫“鸡飞狗跳庄”（日文原文「またずれ荘」，またずれ意为胯疮，也有译作“胯下痛公寓”和“股擦公寓（日文原文的汉字写法）”）的木质结构公寓。<br>六张榻榻米大小，附带厨房，共用厕所（只在原作出现）的生活条件对于四人家庭来说有一些艰苦，但是和邻居第四次复读生四郎、监视贩毒组织的刑事、曾经是特种兵的人妖苏珊小雪、摩洛达西共和国王子偶比古等等的住民一起的鸡飞狗跳的日常当中，逐渐习惯了这样的生活。即使野原家搬回了原来的家中之后也和这些邻居持续保持联络。<br>顺便一提，野原一家搬家的桥段发生的背景发生在2000年《蜡笔小新》连载的杂志从「週刊漫画アクション」到「月刊マンガタウン」的时间，那时臼井老师提议说“正好连载的杂志也要换（原文为“引っ越す”，意为搬家），那干脆把小新的家给炸了吧！”<br>但是，这段故事破例的点在于，在鸡飞狗跳庄居住的故事连载了将近一年。通常的搞笑漫画里面，第二周的连载可能家里的房子就恢复原状了，但是臼井老师为了保护漫画的真实感，做出了类似于“家里烧了还需要报保险”，“重建房子的时候就住到公寓里面去”，“这重建怎么也得花一年时间吧”等等很具现实性的构思，以此为基础制作了这些故事。即使看起来像是闹剧一般的鸡飞狗跳庄的生活，也是凝练了野原一家日常精髓的故事篇章。这样的真实感，或许也是《蜡笔小新》大受追捧的原因之一也说不定。</p><h2 id="连野原家都不知道的小白的那些一技之长"><a href="#连野原家都不知道的小白的那些一技之长" class="headerlink" title="连野原家都不知道的小白的那些一技之长"></a>连野原家都不知道的小白的那些一技之长</h2><p>被扔在路边，后来被新之助捡回家的杂种狗小白。作为野原家的狗，小白从连载初期就登场，和新之助是很亲很亲的好友。作为在家里养小白的交换条件，新之助和美冴约定到“自己照顾小白”，但是由于新之助在喂食和散步这样的事情上不断偷懒，所以后来小白发现自己变成什么都会做的能干小狗了。<br>例如，小白自己给自己准备饲料，已经成为了野原家的日常状态。在没人看见的时候，小白会自己把狗食拖出来吃，或者在商店街表演杂技踩球或者倒立帮助店家招揽客人，店家为了感谢小白而给它食物。又或者，在散步途中，新之助被美女姐姐给吸引走的时候，小白也会自己从项圈钻出来，然后自己去散步一圈，然后再钻回项圈里，当作无事发生。这样的技能野原家当然是不知道，被误解为小白没散步，没吃东西也是经常的事。<br>随着系列故事的进展，小白的技能也在不断进化，终于，小白还学会了“下雨了把晒的衣服收进房间”、“给院子里的小萝卜浇水”，“代替新之助去菜店，买回来正好数量的生姜”等等跟人一样的技能。不过，小白像它主人一样，也有见到可爱的母狗就丧失思考能力，色眯眯地去搭讪的一面。<br>动画里小白的配音演员是真柴摩利，真柴不仅负责了小白的声音，还同时负责了风间的声音。在以小白和风间为主角的动画第564集《风间和小白去散步》中可以感受到真柴一人分饰两角的厉害之处。</p><h2 id="小葵的名字是通过向动画观众的公开征集决定的"><a href="#小葵的名字是通过向动画观众的公开征集决定的" class="headerlink" title="小葵的名字是通过向动画观众的公开征集决定的"></a>小葵的名字是通过向动画观众的公开征集决定的</h2><p>原作中在「週刊漫画アクション」的1996年8月20日刊，动画则是同年的9月27日的放送中登场的新之助的妹妹“野原向日葵”，仿佛是完美继承了妈妈美冴的DNA一般，喜欢宝石之类闪闪发光的东西和帅哥。广治或者新之助哄小葵的时候，只有戴上泷泽秀明或者木村拓哉之类杰尼斯系的帅哥的脸剪下来做成的面具才有效果。同时，小葵对于美女抱有很大的敌意，经常很露骨地表现出不爽的情绪。<br>虽然是半岁小孩，但活力一点也不输新之助的小葵的名字，是向动画观众公开募集决定的。据说栏目组收到了几十万张参与募集的明信片，光是写着女孩子名字的明信片就有上千张。之后，从成千上万张明信片中，臼井老师慎重地选出了“向日葵”，作为了新之助妹妹的名字。<br>在动画的故事中，野原家全员都根据自己的名字给出了新生儿名字的建议，新之助提出了“阿新”，美冴提出了“美沙子”，广治提出了“广美”，结果到出生后都还没办法决定下来，只好让过来庆祝出生的爷爷野原银之介来帮大家做决定。<br>于是银之介提出，作为野原家的传统，大家把自己想的名字写在纸上折成纸飞机，飞得最远的纸飞机里面写的名字就是宝宝的名字。最后，新之助想的“向日葵”最终成了宝宝的名字。也就是说，在故事中，给小葵起名字的其实是新之助。</p><h2 id="美冴是摩斯族？原作漫画中出场的令人意外的乐队"><a href="#美冴是摩斯族？原作漫画中出场的令人意外的乐队" class="headerlink" title="美冴是摩斯族？原作漫画中出场的令人意外的乐队"></a>美冴是摩斯族？原作漫画中出场的令人意外的乐队</h2><p>虽然是作为普通上班族野原广志的老婆，但是美冴喜欢的男生类型是凯文·克斯纳、布拉德·皮特、莱昂纳多·迪卡普里奥这样的海外演员。除此之外也喜欢裴勇俊和朴容夏这样的韩流明星，可以看出大概是一个朝三暮四随随便便的人。<br>但是，这样的美冴在音乐方面的兴趣却不太随便。在原作的第14卷，美冴打开刚买的CD播放器，一边听音乐一边喝咖啡，那时听的是“THE COLLECTORS”（日本乐队）的音乐。这个乐队是深受谁人乐队、平克·弗洛伊德等英国摇滚的影响的摇滚乐队，是日本的摩德音乐的代表人物。也就是说，美冴的音乐品味，不仅不随便，反而还能感觉到相当的执着。<br>虽然不知道美冴喜欢THE COLLECTORS的理由，但是根据原作的由来来讲，据说这和到2016为止都在动画中为广治配音的藤原启治老师是THE COLLECTORS里古市コータロー的高中同学有一定的关系。藤原老师和古市老师曾经一起组过乐队，据说到现在也是很亲的朋友。<br>古市老师自己也曾经出现在漫画里过。在东京站迎接派遣大阪一个月返家广治的美冴，在月台上遇见了“THE COLLECTORS的コータロー”（原作第11卷）。这时候的美冴过于兴奋，和其他粉丝一起把コータロー团团围住，把接广治的事情忘得一干二净。</p><h2 id="新之助喜欢的“大姐姐”有特定的倾向吗"><a href="#新之助喜欢的“大姐姐”有特定的倾向吗" class="headerlink" title="新之助喜欢的“大姐姐”有特定的倾向吗"></a>新之助喜欢的“大姐姐”有特定的倾向吗</h2><p>遇见漂亮的女性就失去控制，马上去搭讪问“大姐姐，你吃纳豆加葱吗？”的新之助。据至今作品中出现过的名字或拥有的写真集，新之助喜欢的女性有冈本夏生、小宫悦子、宫泽理惠、加藤礼子、藤原纪香、雏形明子、细川文江、佐藤珠绪、松隆子、内田有纪、梨爱、辰巳奈都子、小池荣子、市川由衣、MEGUMI、井上和香、根本晴美、松岛菜菜子、田中丽奈、堀北真希、女子十二乐坊、后藤真希等等。<br>而这样的无法招架美女的性格又是和广治和银之介完全一样，好像可以说是完全的遗传，但是新之助断言说恋爱对象一定要是“20岁到34岁的美女”，好像又有比爸爸和爷爷更大的执着。实际上，被喜欢新之助的幼儿园同学酢乙女爱告白的时候，新之助说“我对小孩子没兴趣”。<br>但是在电影《夕阳下的春日部男孩》中，新之助又喜欢上14岁的椿，这不符合之前讲的“20岁到34岁的美女”，所以也许只要是“比自己年纪大的美女”的话，是什么类型的也不重要了。尤其是能够瞬间看出对方是不是美女的能力也不一般，例如瞬间就看出戴了眼镜的上尾老师是个美女。<br>虽然新之助整天对不同的美女移情别恋，但是20岁女大学生大原娜娜子是贯彻整个系列都一直喜欢的女性。连大人们都讨厌的“光屁屁星人”也能模仿的娜娜子非常喜欢新之助。但是说到底也只是好朋友的程度，娜娜子喜欢的男生类型是相扑运动员，和新之助完全不是同一型的。小新，可惜啊！</p><h2 id="让黑道脸的园长老师开幼儿园的那次相遇"><a href="#让黑道脸的园长老师开幼儿园的那次相遇" class="headerlink" title="让黑道脸的园长老师开幼儿园的那次相遇"></a>让黑道脸的园长老师开幼儿园的那次相遇</h2><p>新之助上的幼儿园，原作中的动感幼儿园，动画中的双叶幼儿园，是吉永绿、松坂梅、上尾增美等老师上班的地方。虽然老师们也有这样那样的特别之处，但在这里想要特别讲的是园长老师。因为一直待着墨镜，长得像黑社会，所以被新之助一直叫作“组长”。<br>但是，实际上园长老师非常喜欢小孩子，一直亲自开校车、亲自站在门口送迎小朋友，所以对于被新之助叫作组长一事其实本人很伤心。这样的话，起码把墨镜摘一下吧……虽然很想这样讲，但是摘掉墨镜之后的脸更加恐怖，不仅是老婆，自己对着镜子看了都会被吓到的程度。这样的园长老师为什么要开幼儿园呢？<br>年轻的时候，为了求学而来到东京的园长老师，因为自己长得恐怖被周围的人都避而远之而非常失落。“我真的能坚持下去吗……？”这样苦恼着的时候，有一个不怕他的小男孩很亲切地和他搭话了。“小朋友不怕哥哥吗？”“不怕，哥哥看起来很温柔不是吗？”被这样的不以貌取人的小孩子的纯真打动，园长老师从而下定决心“要成为能帮助小朋友的人”（原作39卷）。这一个刚来到东京时的故事对于园长实在是印象深刻，所以园长把这一天定为“上京纪念日”，每年的这一天幼儿园都会放假。<br>因为是一个很善良温柔的人，所以在幼儿园里被小朋友和老师们都尊敬着。在动画系列中，2000年还播送了《战斗吧！园长超人！》的动画短片。</p><h2 id="在漫画和动画的投接球中不断进化的角色们"><a href="#在漫画和动画的投接球中不断进化的角色们" class="headerlink" title="在漫画和动画的投接球中不断进化的角色们"></a>在漫画和动画的投接球中不断进化的角色们</h2><p>从1992年4月13日动画的播放开始到现在，在这28年的历史中，也有角色是通过动画获得人气的。例如新之助很爱看的特摄节目主角“动感超人”。原作漫画中大概也就出现了一格左右，但是在动画里作为一个剧中剧不断发展，后来甚至在《蜡笔小新》中占有了一席之地。在小孩中也变得相当有人气，电影第一作《动感超人大战泳装魔王》中，成为了出现在标题里的作品中的重要角色。<br>原作中作为新之助的玩具登场的“康达姆机器人”也是在动画系列中被扩张其设定，后来也衍生出剧中剧《超电导康达姆机器人》。放送开始时的专属的主题歌和片头也获得了相当的人气。后来更是在2014年的电影《大对决！机器人爸爸的反击》中实现到电影中电影的进化。<br>同样的，动感超人也时不时出现在系列中，甚至在原作41卷中出现了其后继者“动感超人女儿”。2013年开始「月刊アクション」还开始连载动感超人的外传作品。动感超人和康达姆机器人就是这样的在漫画中只是不经意被画到，其设定又在在动画中被扩充，后来又以更丰满的样子回到原作的，在如同是漫画和动画的幸福的投接球的过程中的不断进化的角色，现在已经是系列中不可或缺的角色。</p><br><p>-全文完-</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a data-flickr-embed=&quot;true&quot; href=&quot;https://www.flickr.com/photos/193508450@N06/51320785154/in/dateposted-public/&quot; title=&quot;shinchan&quot;&gt;&lt;img sr</summary>
      
    
    
    
    
    <category term="Chinese" scheme="https://blog.yuan-cong.com/tags/Chinese/"/>
    
    <category term="Translation" scheme="https://blog.yuan-cong.com/tags/Translation/"/>
    
  </entry>
  
  <entry>
    <title>リフレーム</title>
    <link href="https://blog.yuan-cong.com/2020/01/12/%E3%83%AA%E3%83%95%E3%83%AC%E3%83%BC%E3%83%A0/"/>
    <id>https://blog.yuan-cong.com/2020/01/12/%E3%83%AA%E3%83%95%E3%83%AC%E3%83%BC%E3%83%A0/</id>
    <published>2020-01-12T09:45:26.000Z</published>
    <updated>2021-07-19T09:46:18.122Z</updated>
    
    <content type="html"><![CDATA[<p>現在では、科学技術や社会価値の変遷に適応するため、現代デザインには「リフレーム」の概念が用いられる場合は少なくはない。私は、リフレームに最も重要なポイントは人の固有印象を変容させ、様々な物事から長所を抽出し、組み合わせ、マイナスをプラスに転変することから人の価値観を変えることだと思う。<br>2006年、据置型ゲーム機Wiiの発売はゲーム機インタラクションの革命を起こした。300万本越えの売り上げを記録したWii SportsやWii Fitらのソフトウェアはいつものスポーツシミュレーション機とは違い、ゲームプレイヤーが馴染んでいるゲーム要素が巧みに入れられたため、運動が苦手な人も夢中になった。その例から、運動という、私みたいな人に対してマイナスなことを、ゲームという楽しくてプラスなことと組み合わせ、所謂ゲミフィケーションの手段で、大勢な人の運動不足の改善に役に立った。<br>とはいえ、上述のような方法の成功はたやすくないと言われている。情報学研究者の栗原によると、ただのプラスの方の要素羅列だけでは、反作用が生まれかねない。ゲミフィケーションを例として説明する。第一、マイナスな部分をプラスに変容させるように使う手段のため、バランスの取りようによって、仕事のゲーム化もゲームの仕事化になりうる。第二、目標の達成と共に、ユーザーはどのようなボーナスが欲しがっているのかは工夫して考慮すべき問題である。そのため、ゲミフィケーションのような手段は、ユーザーが本来マイナスからプラスへ転換する方法の提供役であるべきで、辛くてつまらないことから、楽しいことへ変容させることが可能にする。<br>Wiiの後継者として、Nintendo Switchの誕生は様々なリフレームの可能性のインキュベーターと考えられ、Joy-conの組み立て方によって、リアル生活中の仕草を模倣する可能性も生まれる。特にリングフィットアドベンチャーの発売は、Switchの長所を活かし、Wii Sportsの取得した成果をもう一層に推進した。均衡に取れたRPG冒険とトレイニングのバランスと健全なカスタマイズシステムでは、ゲームの運動化にならず、ユーザーが自分に合うトレイニングコースを行えると共に、ゲームの楽しさも楽しめる。それに、有効な可視化機能はユーザーの成果を焦る気持ちを満足させ、自分の少しの動きも体の健康に貢献しているとユーザーに実感させることができる。そのため、ゲームというプラスなもので、固有印象でもある「運動の辛さ」を中和させ、主要目標はカロリーを消費することから、敵を倒しながら色々なアイテムを収集することに転変し、運動は面白いと思わせることができた。<br>任天堂はゲーム会社とはいえ、面白いゲームを開発することだけではなく、ゲームの面白さで社会の退屈さを変えるのにも取り組んでいる。運動のみならず、苦手や嫌いだと感じるものが、自分や社会にとってプラスを与える物事が沢山ある。リフレームの手法で変容させるのもデザインの大切な役割だと思う。<br><br></p><p>-終わり-</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;現在では、科学技術や社会価値の変遷に適応するため、現代デザインには「リフレーム」の概念が用いられる場合は少なくはない。私は、リフレームに最も重要なポイントは人の固有印象を変容させ、様々な物事から長所を抽出し、組み合わせ、マイナスをプラスに転変することから人の価値観を変えるこ</summary>
      
    
    
    
    
    <category term="Japanese" scheme="https://blog.yuan-cong.com/tags/Japanese/"/>
    
    <category term="Work" scheme="https://blog.yuan-cong.com/tags/Work/"/>
    
  </entry>
  
  <entry>
    <title>苦手なものを好きなものに変える方法</title>
    <link href="https://blog.yuan-cong.com/2020/01/12/%E8%8B%A6%E6%89%8B%E3%81%AA%E3%82%82%E3%81%AE%E3%82%92%E5%A5%BD%E3%81%8D%E3%81%AA%E3%82%82%E3%81%AE%E3%81%AB%E5%A4%89%E3%81%88%E3%82%8B%E6%96%B9%E6%B3%95/"/>
    <id>https://blog.yuan-cong.com/2020/01/12/%E8%8B%A6%E6%89%8B%E3%81%AA%E3%82%82%E3%81%AE%E3%82%92%E5%A5%BD%E3%81%8D%E3%81%AA%E3%82%82%E3%81%AE%E3%81%AB%E5%A4%89%E3%81%88%E3%82%8B%E6%96%B9%E6%B3%95/</id>
    <published>2020-01-12T09:42:22.000Z</published>
    <updated>2021-07-19T09:45:05.145Z</updated>
    
    <content type="html"><![CDATA[<h3 id="問-1"><a href="#問-1" class="headerlink" title="問 1"></a>問 1</h3><p>苦手なものを一つ選び、自身の知り得る情報やこれまでの体験などをもとに、 その理由や背景について 400 字程度で記述しなさい。</p><h3 id="回答"><a href="#回答" class="headerlink" title="回答"></a>回答</h3><p>「好き」なものに変えたい「苦手」なものというのは、有益なものだと知っているとはいえ、自分の好き嫌いや根性の無さで「やりたくない」あるいは「続けない」ものだと思う。<br>私の場合、小さい頃、中耳炎の治療で10年以上続けて肥ったことがある。しかし、私は運動が「苦手」で、何回もダイエットしたが、成功せずに終わってしまい、肥った状態が10年以上続くと、高血圧などの症状まで出た結果だった。その時私、実はダイエットのメリットや必要性をはっきり分かっていた。しかし、残念ながら、「食べたい」「座りたい」「運動したくない」気持ちはダイエットする思惑に勝っていた。<br>自分のこの経験からまとめると、あるものが「苦手」になる理由は以下となる。第一、面白くないからだ。個人的に面白くないものにはやる気のない状態であるため、「苦手」となるのも自然の成り行きである。第二、成果が出て来ないからだ。この成果に関しては特に速度が重要である。成果が出るまでかなり時間がかかる過程にはうんざりして不自信になりやすいため、「苦手」と間違える可能性がある。第三、根性がなく、体力や脳力が費やされる仕事が嫌いだからだ。人には安易な生活を求め、苦労や工夫することを避けるきらいがあるからだと思う。</p><h3 id="問-2"><a href="#問-2" class="headerlink" title="問 2"></a>問 2</h3><p>苦手なものを好きなものに変える方法について、問 1 で述べた具体例とその 理由や背景を関連付けながら自身の制作や研究分野の視点から 800 字程度で 説明しなさい。</p><h3 id="回答-1"><a href="#回答-1" class="headerlink" title="回答"></a>回答</h3><p>苦手なものを好きなものに変えるに、私がフォーカスしたいのはゲミフィケーションというキーワードだ。<br>「ゲーム」は人に「楽しい」印象を与えるため、苦手なものを変容させるには、ゲーム性の追加は有効だと考えられる。好きなものにするために、まずは興味を持たせることだと思う。Appleが開発したiPadアプリPlaygroundは、子供向けのプログラミング基礎の勉強アプリで、Swift言語の基礎をいくつかのエピソードに分け、面白い物語やアトラクティブなキャラクターと組み合わせ、子供が楽しめながら知識を学べる冒険ゲームである。遊ぶのは子供の天性で、勉強することに抵触感を持つのは当然なこととはいえ、天性の利用しようによっても「勉強じゃない、遊びだ」と子供に思わせるのだ。<br>子供のみならず、遊ぶのは人間の天性でもあるため、ゲミフィケーションは大人にも効く。例えば、上述した私の運動不足を改善してくれた任天堂のリングフィットアドベンチャーは、RPGと融合したトレイニング体感ゲームである。ゲミフィケーションにおけ、プレイヤー達のゲームへの興味を利用し、見事に運動をゲームへの変容を遂げ、目標をカロリーを消費することから、敵を倒しながら色々なアイテムを収集することに転変した。<br>以上のプロダクトは上述の三つの問題を完璧に解決している。第一、ゲーム自体が面白いため、ユーザーの意欲を喚起することができる。第二、成果を体にはっきり反映されかねるが、ゲームにはちゃんとした可視化手段が取られ、どのぐらい進展しているかをユーザーに知らせる、つまり、即時に成果を実感させることができる。第三、「運動しているのではなく、体の動きで敵を倒してレベルアップしているのだ」と、目標達成と同時に、ユーザーは辛く難しいタスクから楽しいゲームへ転換することができる。<br>私の研究分野の視点から見ると、公共資源や環境の保護が一般人に、どの程度できているのか、あるいは自分のやり方が正しいかどうかは不明瞭なため、苦手に感じる場合は多いだろう。ゲミフィケーションの方法を応用すると、面白い形式・斬新なインタラクション ・豊かな可視化手段で人々の向社会の行為を励ましていくのだろう。<br><br></p><p>-終わり-</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;問-1&quot;&gt;&lt;a href=&quot;#問-1&quot; class=&quot;headerlink&quot; title=&quot;問 1&quot;&gt;&lt;/a&gt;問 1&lt;/h3&gt;&lt;p&gt;苦手なものを一つ選び、自身の知り得る情報やこれまでの体験などをもとに、 その理由や背景について 400 字程度で記述しなさい。&lt;/p</summary>
      
    
    
    
    
    <category term="Japanese" scheme="https://blog.yuan-cong.com/tags/Japanese/"/>
    
    <category term="Work" scheme="https://blog.yuan-cong.com/tags/Work/"/>
    
  </entry>
  
  <entry>
    <title>Documentary &quot;Nian&#39; Nian&quot; (念念)</title>
    <link href="https://blog.yuan-cong.com/2018/09/01/Documentary-Nian-Nian/"/>
    <id>https://blog.yuan-cong.com/2018/09/01/Documentary-Nian-Nian/</id>
    <published>2018-09-01T07:48:07.000Z</published>
    <updated>2021-07-19T08:25:17.398Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube.com/embed/QocgLpdHsrw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br><i>[Eng/Jpn/Chn sub] Documentary "Nian' Nian" (念念)"</i>]]></content>
    
    
      
      
    <summary type="html">&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/QocgLpdHsrw&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;acceler</summary>
      
    
    
    
    
    <category term="Chinese" scheme="https://blog.yuan-cong.com/tags/Chinese/"/>
    
    <category term="English" scheme="https://blog.yuan-cong.com/tags/English/"/>
    
    <category term="Japanese" scheme="https://blog.yuan-cong.com/tags/Japanese/"/>
    
    <category term="Work" scheme="https://blog.yuan-cong.com/tags/Work/"/>
    
  </entry>
  
</feed>
